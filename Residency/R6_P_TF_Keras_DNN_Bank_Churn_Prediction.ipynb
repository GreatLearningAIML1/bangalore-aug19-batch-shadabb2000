{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zUZjPnVXGz0Z"
   },
   "source": [
    "# The Bank Churn Prediction\n",
    "Given a Bank customer, can we build a classifier that can determine whether they will leave or not using Neural networks?\n",
    "\n",
    "The dataset contains 10,000 sample points with 14 distinct features such as CustomerId, CreditScore, Geography, Gender, Age, Tenure, Balance etc. Know your data: https://www.kaggle.com/barelydedicated/bank-customer-churn-modeling\n",
    "\n",
    " \n",
    "\n",
    "Context:\n",
    "Businesses like banks which provide service have to worry about problem of 'Churn' i.e. customers leaving and joining another service provider. It is important to understand which aspects of the service influence a\n",
    "customer's decision in this regard. Management can concentrate efforts on improvement of service, keeping in mind these priorities.\n",
    "\n",
    "Steps and Milestones (100%):\n",
    "\n",
    "\n",
    " Setup Environment and Load Necessary Packages (5%)\n",
    "\n",
    " Data Preparation (40%)\n",
    "o Loading Data (5%)\n",
    "o Cleaning Data (10%)\n",
    "o Data Representation & Feature Engineering (If Any) (15%)\n",
    "o Creating Train and Validation Set (10%)\n",
    "\n",
    " Model Creation (30%)\n",
    "o Write & Configure Model (10%)\n",
    "o Compile Model (10%)\n",
    "o Build Model & Checking Summary (10%)\n",
    "\n",
    " Training and Evaluation (25%)\n",
    "o Run Multiple Experiments (10%)\n",
    "o Reason & Visualize Model Performance (5%)\n",
    "o Evaluate Model on Test Set (10%)\n",
    "\n",
    "Learning Outcomes:\n",
    "o Neural Networks for Predictive Analytics\n",
    "o Fine-tuning Model\n",
    "o Data Preparation\n",
    "o Feature Engineering\n",
    "o Visualization\n",
    "\n",
    " \n",
    "\n",
    "The points distribution for this case is as follows:\n",
    "\n",
    "Read the data set\n",
    "Drop the columns which are unique for all users like IDs (2.5 points)\n",
    "Distinguish the feature and target set (2.5 points)\n",
    "Divide the data set into training and test sets ( 2.5 points)\n",
    "Normalize the train and test data (5 points)\n",
    "Initialize & build the model (10 points)\n",
    "Predict the results using 0.5 as a threshold (5 points)\n",
    "Print the Accuracy score and confusion matrix (2.5 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RMbmpriavLE9"
   },
   "source": [
    "### Specifying the TensorFlow version\n",
    "Running `import tensorflow` will import the default version (currently 1.x). You can use 2.x by running a cell with the `tensorflow_version` magic **before** you run `import tensorflow`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fu8bUU__oa7h"
   },
   "outputs": [],
   "source": [
    "# %tensorflow_version 2.x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bLz1Ckvfvn6D"
   },
   "source": [
    "### Import TensorFlow\n",
    "Once you have specified a version via this magic, you can run `import tensorflow` as normal and verify which version was imported as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CWrzVTLOvn6M"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_uYeJgkNuXNC"
   },
   "source": [
    "### Set random seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lcASNsewsfQX"
   },
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kE0EDKvQhEIe"
   },
   "source": [
    "### Import dataset\n",
    "- Import Bank Churn Dataset\n",
    "- Importing the dataset using the pandas library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IOOWpD26Haq3"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CustomerId</th>\n",
       "      <th>Surname</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RowNumber</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15634602</td>\n",
       "      <td>Hargrave</td>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15647311</td>\n",
       "      <td>Hill</td>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15619304</td>\n",
       "      <td>Onio</td>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15701354</td>\n",
       "      <td>Boni</td>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>15737888</td>\n",
       "      <td>Mitchell</td>\n",
       "      <td>850</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           CustomerId   Surname  CreditScore Geography  Gender  Age  Tenure  \\\n",
       "RowNumber                                                                     \n",
       "1            15634602  Hargrave          619    France  Female   42       2   \n",
       "2            15647311      Hill          608     Spain  Female   41       1   \n",
       "3            15619304      Onio          502    France  Female   42       8   \n",
       "4            15701354      Boni          699    France  Female   39       1   \n",
       "5            15737888  Mitchell          850     Spain  Female   43       2   \n",
       "\n",
       "             Balance  NumOfProducts  HasCrCard  IsActiveMember  \\\n",
       "RowNumber                                                        \n",
       "1               0.00              1          1               1   \n",
       "2           83807.86              1          0               1   \n",
       "3          159660.80              3          1               0   \n",
       "4               0.00              2          0               0   \n",
       "5          125510.82              1          1               1   \n",
       "\n",
       "           EstimatedSalary  Exited  \n",
       "RowNumber                           \n",
       "1                101348.88       1  \n",
       "2                112542.58       0  \n",
       "3                113931.57       1  \n",
       "4                 93826.63       0  \n",
       "5                 79084.10       0  "
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "df = pd.read_csv(\"R6_data/bank_churn_data.csv\", index_col='RowNumber')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>unique</th>\n",
       "      <th>top</th>\n",
       "      <th>freq</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>CustomerId</th>\n",
       "      <td>10000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.56909e+07</td>\n",
       "      <td>71936.2</td>\n",
       "      <td>1.55657e+07</td>\n",
       "      <td>1.56285e+07</td>\n",
       "      <td>1.56907e+07</td>\n",
       "      <td>1.57532e+07</td>\n",
       "      <td>1.58157e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Surname</th>\n",
       "      <td>10000</td>\n",
       "      <td>2932</td>\n",
       "      <td>Smith</td>\n",
       "      <td>32</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CreditScore</th>\n",
       "      <td>10000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>650.529</td>\n",
       "      <td>96.6533</td>\n",
       "      <td>350</td>\n",
       "      <td>584</td>\n",
       "      <td>652</td>\n",
       "      <td>718</td>\n",
       "      <td>850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Geography</th>\n",
       "      <td>10000</td>\n",
       "      <td>3</td>\n",
       "      <td>France</td>\n",
       "      <td>5014</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gender</th>\n",
       "      <td>10000</td>\n",
       "      <td>2</td>\n",
       "      <td>Male</td>\n",
       "      <td>5457</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Age</th>\n",
       "      <td>10000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>38.9218</td>\n",
       "      <td>10.4878</td>\n",
       "      <td>18</td>\n",
       "      <td>32</td>\n",
       "      <td>37</td>\n",
       "      <td>44</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tenure</th>\n",
       "      <td>10000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0128</td>\n",
       "      <td>2.89217</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Balance</th>\n",
       "      <td>10000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>76485.9</td>\n",
       "      <td>62397.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>97198.5</td>\n",
       "      <td>127644</td>\n",
       "      <td>250898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NumOfProducts</th>\n",
       "      <td>10000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.5302</td>\n",
       "      <td>0.581654</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HasCrCard</th>\n",
       "      <td>10000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.7055</td>\n",
       "      <td>0.45584</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IsActiveMember</th>\n",
       "      <td>10000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.5151</td>\n",
       "      <td>0.499797</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <td>10000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100090</td>\n",
       "      <td>57510.5</td>\n",
       "      <td>11.58</td>\n",
       "      <td>51002.1</td>\n",
       "      <td>100194</td>\n",
       "      <td>149388</td>\n",
       "      <td>199992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Exited</th>\n",
       "      <td>10000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.2037</td>\n",
       "      <td>0.402769</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 count unique     top  freq         mean       std  \\\n",
       "CustomerId       10000    NaN     NaN   NaN  1.56909e+07   71936.2   \n",
       "Surname          10000   2932   Smith    32          NaN       NaN   \n",
       "CreditScore      10000    NaN     NaN   NaN      650.529   96.6533   \n",
       "Geography        10000      3  France  5014          NaN       NaN   \n",
       "Gender           10000      2    Male  5457          NaN       NaN   \n",
       "Age              10000    NaN     NaN   NaN      38.9218   10.4878   \n",
       "Tenure           10000    NaN     NaN   NaN       5.0128   2.89217   \n",
       "Balance          10000    NaN     NaN   NaN      76485.9   62397.4   \n",
       "NumOfProducts    10000    NaN     NaN   NaN       1.5302  0.581654   \n",
       "HasCrCard        10000    NaN     NaN   NaN       0.7055   0.45584   \n",
       "IsActiveMember   10000    NaN     NaN   NaN       0.5151  0.499797   \n",
       "EstimatedSalary  10000    NaN     NaN   NaN       100090   57510.5   \n",
       "Exited           10000    NaN     NaN   NaN       0.2037  0.402769   \n",
       "\n",
       "                         min          25%          50%          75%  \\\n",
       "CustomerId       1.55657e+07  1.56285e+07  1.56907e+07  1.57532e+07   \n",
       "Surname                  NaN          NaN          NaN          NaN   \n",
       "CreditScore              350          584          652          718   \n",
       "Geography                NaN          NaN          NaN          NaN   \n",
       "Gender                   NaN          NaN          NaN          NaN   \n",
       "Age                       18           32           37           44   \n",
       "Tenure                     0            3            5            7   \n",
       "Balance                    0            0      97198.5       127644   \n",
       "NumOfProducts              1            1            1            2   \n",
       "HasCrCard                  0            0            1            1   \n",
       "IsActiveMember             0            0            1            1   \n",
       "EstimatedSalary        11.58      51002.1       100194       149388   \n",
       "Exited                     0            0            0            0   \n",
       "\n",
       "                         max  \n",
       "CustomerId       1.58157e+07  \n",
       "Surname                  NaN  \n",
       "CreditScore              850  \n",
       "Geography                NaN  \n",
       "Gender                   NaN  \n",
       "Age                       92  \n",
       "Tenure                    10  \n",
       "Balance               250898  \n",
       "NumOfProducts              4  \n",
       "HasCrCard                  1  \n",
       "IsActiveMember             1  \n",
       "EstimatedSalary       199992  \n",
       "Exited                     1  "
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe(include='all').transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HERt3drbhX0i"
   },
   "source": [
    "### Drop the columns which are unique for all users\n",
    "- Dropping CustomerId\n",
    "- Can try dropping surname as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0cV-_qHAHyvE"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 10000 entries, 1 to 10000\n",
      "Data columns (total 11 columns):\n",
      "CreditScore        10000 non-null int64\n",
      "Geography          10000 non-null object\n",
      "Gender             10000 non-null object\n",
      "Age                10000 non-null int64\n",
      "Tenure             10000 non-null int64\n",
      "Balance            10000 non-null float64\n",
      "NumOfProducts      10000 non-null int64\n",
      "HasCrCard          10000 non-null int64\n",
      "IsActiveMember     10000 non-null int64\n",
      "EstimatedSalary    10000 non-null float64\n",
      "Exited             10000 non-null int64\n",
      "dtypes: float64(2), int64(7), object(2)\n",
      "memory usage: 937.5+ KB\n"
     ]
    }
   ],
   "source": [
    "df_drop = df.drop(['CustomerId','Surname'],axis=1) ## Removing surname as onhot encoding will cause issues for each one of them\n",
    "df_drop.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoding and scaling values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 10000 entries, 1 to 10000\n",
      "Data columns (total 11 columns):\n",
      "CreditScore        10000 non-null int64\n",
      "Geography          10000 non-null int64\n",
      "Gender             10000 non-null int64\n",
      "Age                10000 non-null int64\n",
      "Tenure             10000 non-null int64\n",
      "Balance            10000 non-null float64\n",
      "NumOfProducts      10000 non-null int64\n",
      "HasCrCard          10000 non-null int64\n",
      "IsActiveMember     10000 non-null int64\n",
      "EstimatedSalary    10000 non-null float64\n",
      "Exited             10000 non-null int64\n",
      "dtypes: float64(2), int64(9)\n",
      "memory usage: 937.5 KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "## Label Encoding of all the columns\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "# instantiate labelencoder object\n",
    "le = LabelEncoder()\n",
    "\n",
    "# Categorical boolean mask\n",
    "categorical_feature_mask = df_drop.dtypes==object\n",
    "# filter categorical columns using mask and turn it into a list\n",
    "categorical_cols = df_drop.columns[categorical_feature_mask].tolist()\n",
    "df_drop[categorical_cols] = df_drop[categorical_cols].apply(lambda col: le.fit_transform(col))\n",
    "print(df_drop.info())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RowNumber</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>619</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>608</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>502</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>699</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>850</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           CreditScore  Geography  Gender  Age  Tenure    Balance  \\\n",
       "RowNumber                                                           \n",
       "1                  619          0       0   42       2       0.00   \n",
       "2                  608          2       0   41       1   83807.86   \n",
       "3                  502          0       0   42       8  159660.80   \n",
       "4                  699          0       0   39       1       0.00   \n",
       "5                  850          2       0   43       2  125510.82   \n",
       "\n",
       "           NumOfProducts  HasCrCard  IsActiveMember  EstimatedSalary  Exited  \n",
       "RowNumber                                                                     \n",
       "1                      1          1               1        101348.88       1  \n",
       "2                      1          0               1        112542.58       0  \n",
       "3                      3          1               0        113931.57       1  \n",
       "4                      2          0               0         93826.63       0  \n",
       "5                      1          1               1         79084.10       0  "
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_drop.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 1 ... 1 1 0]\n",
      "[[-0.32622142 -0.90188624 -1.09598752 ...  0.64609167  0.97024255\n",
      "   0.02188649]\n",
      " [-0.44003595  1.51506738 -1.09598752 ... -1.54776799  0.97024255\n",
      "   0.21653375]\n",
      " [-1.53679418 -0.90188624 -1.09598752 ...  0.64609167 -1.03067011\n",
      "   0.2406869 ]\n",
      " ...\n",
      " [ 0.60498839 -0.90188624 -1.09598752 ... -1.54776799  0.97024255\n",
      "  -1.00864308]\n",
      " [ 1.25683526  0.30659057  0.91241915 ...  0.64609167 -1.03067011\n",
      "  -0.12523071]\n",
      " [ 1.46377078 -0.90188624 -1.09598752 ...  0.64609167 -1.03067011\n",
      "  -1.07636976]]\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import zscore\n",
    "df_scaled = df_drop.apply(zscore)\n",
    "X_columns =  df_scaled.columns.tolist()[0:10]\n",
    "Y_Columns = df_drop.columns.tolist()[-1:]\n",
    "\n",
    "X = df_scaled[X_columns].values # Credit Score through Estimated Salary\n",
    "Y = np.array(df_drop['Exited']) # Exited\n",
    "\n",
    "print(Y)\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3YErwYLCH0N_"
   },
   "source": [
    "### Create train and test data\n",
    "- use train_test_split to get train and test set\n",
    "- set a random_state\n",
    "- test_size: 0.20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TYKNJL85h7pQ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 1 ... 1 1 0]\n",
      "bool\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "print(Y)\n",
    "\n",
    "Y = Y.astype('bool_')\n",
    "print(Y.dtype)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.20, random_state=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "R9vv-_gpyLY9"
   },
   "outputs": [],
   "source": [
    "# from tensorflow.keras.utils import to_categorical\n",
    "# #Encoding the output class label (One-Hot Encoding)\n",
    "# y_train=to_categorical(y_train,3,dtype='int')\n",
    "# y_test=to_categorical(y_test,3,dtype='int')\n",
    "\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "#Encoding the output class label (One-Hot Encoding)\n",
    "y_train=to_categorical(y_train,2,dtype='int')\n",
    "y_test=to_categorical(y_test,2,dtype='int')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hbIFzoPNSyYo"
   },
   "source": [
    "### Initialize a sequential model\n",
    "- Define a sequential model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4FvSbf1UjHtl"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras.layers import Dense\n",
    "#Initialize Sequential Graph (model)\n",
    "model = tf.keras.Sequential()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "72ibK5Jxm8iL"
   },
   "source": [
    "### Add a layer\n",
    "- Use Dense Layer  with input shape of 4 (according to the feature set) and number of outputs set to 3\n",
    "- Apply Softmax on Dense Layer outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uZKrBNSRm_o9"
   },
   "outputs": [],
   "source": [
    "#Add Dense layer for prediction - Keras declares weights and bias automatically\n",
    "model.add(Dense(18, activation='relu', input_shape=(10,)))\n",
    "model.add(Dense(20, activation='relu'))\n",
    "model.add(Dense(2, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yJL8n8vcSyYz"
   },
   "source": [
    "### Compile the model\n",
    "- Use SGD as Optimizer\n",
    "- Use categorical_crossentropy as loss function\n",
    "- Use accuracy as metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Tc_-fjIEk1ve"
   },
   "outputs": [],
   "source": [
    "#Compile the model - add Loss and Gradient Descent optimizer\n",
    "model.compile(optimizer='sgd', loss='categorical_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "54ZZCfNGlu0i"
   },
   "source": [
    "### Summarize the model\n",
    "- Check model layers\n",
    "- Understand number of trainable parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "elER3F_4ln8n"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_69\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_272 (Dense)            (None, 18)                198       \n",
      "_________________________________________________________________\n",
      "dense_273 (Dense)            (None, 20)                380       \n",
      "_________________________________________________________________\n",
      "dense_274 (Dense)            (None, 2)                 42        \n",
      "=================================================================\n",
      "Total params: 620\n",
      "Trainable params: 620\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rWdbfFCXmCHt"
   },
   "source": [
    "### Fit the model\n",
    "- Give train data as training features and labels\n",
    "- Epochs: 100\n",
    "- Give validation data as testing features and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cO1c-5tjmBVZ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/100\n",
      "8000/8000 [==============================] - 1s 137us/sample - loss: 0.5676 - accuracy: 0.7401 - val_loss: 0.5063 - val_accuracy: 0.7925\n",
      "Epoch 2/100\n",
      "8000/8000 [==============================] - 1s 64us/sample - loss: 0.4885 - accuracy: 0.7962 - val_loss: 0.4733 - val_accuracy: 0.7940\n",
      "Epoch 3/100\n",
      "8000/8000 [==============================] - 1s 65us/sample - loss: 0.4630 - accuracy: 0.7983 - val_loss: 0.4494 - val_accuracy: 0.7925\n",
      "Epoch 4/100\n",
      "8000/8000 [==============================] - 1s 68us/sample - loss: 0.4440 - accuracy: 0.8051 - val_loss: 0.4301 - val_accuracy: 0.8055\n",
      "Epoch 5/100\n",
      "8000/8000 [==============================] - 1s 65us/sample - loss: 0.4287 - accuracy: 0.8138 - val_loss: 0.4145 - val_accuracy: 0.8215\n",
      "Epoch 6/100\n",
      "8000/8000 [==============================] - 1s 64us/sample - loss: 0.4167 - accuracy: 0.8234 - val_loss: 0.4026 - val_accuracy: 0.8295\n",
      "Epoch 7/100\n",
      "8000/8000 [==============================] - 1s 66us/sample - loss: 0.4073 - accuracy: 0.8286 - val_loss: 0.3932 - val_accuracy: 0.8400\n",
      "Epoch 8/100\n",
      "8000/8000 [==============================] - 1s 64us/sample - loss: 0.3993 - accuracy: 0.8338 - val_loss: 0.3850 - val_accuracy: 0.8420\n",
      "Epoch 9/100\n",
      "8000/8000 [==============================] - 1s 64us/sample - loss: 0.3918 - accuracy: 0.8381 - val_loss: 0.3786 - val_accuracy: 0.8445\n",
      "Epoch 10/100\n",
      "8000/8000 [==============================] - 1s 66us/sample - loss: 0.3854 - accuracy: 0.8405 - val_loss: 0.3736 - val_accuracy: 0.8520\n",
      "Epoch 11/100\n",
      "8000/8000 [==============================] - 1s 66us/sample - loss: 0.3799 - accuracy: 0.8435 - val_loss: 0.3695 - val_accuracy: 0.8540\n",
      "Epoch 12/100\n",
      "8000/8000 [==============================] - 1s 66us/sample - loss: 0.3751 - accuracy: 0.8450 - val_loss: 0.3666 - val_accuracy: 0.8540\n",
      "Epoch 13/100\n",
      "8000/8000 [==============================] - 1s 66us/sample - loss: 0.3712 - accuracy: 0.8470 - val_loss: 0.3645 - val_accuracy: 0.8530\n",
      "Epoch 14/100\n",
      "8000/8000 [==============================] - 1s 66us/sample - loss: 0.3677 - accuracy: 0.8487 - val_loss: 0.3626 - val_accuracy: 0.8540\n",
      "Epoch 15/100\n",
      "8000/8000 [==============================] - 1s 65us/sample - loss: 0.3652 - accuracy: 0.8512 - val_loss: 0.3612 - val_accuracy: 0.8560\n",
      "Epoch 16/100\n",
      "8000/8000 [==============================] - 1s 66us/sample - loss: 0.3627 - accuracy: 0.8515 - val_loss: 0.3602 - val_accuracy: 0.8535\n",
      "Epoch 17/100\n",
      "8000/8000 [==============================] - 1s 67us/sample - loss: 0.3611 - accuracy: 0.8521 - val_loss: 0.3589 - val_accuracy: 0.8565\n",
      "Epoch 18/100\n",
      "8000/8000 [==============================] - 1s 66us/sample - loss: 0.3594 - accuracy: 0.8525 - val_loss: 0.3585 - val_accuracy: 0.8560\n",
      "Epoch 19/100\n",
      "8000/8000 [==============================] - 1s 68us/sample - loss: 0.3580 - accuracy: 0.8529 - val_loss: 0.3579 - val_accuracy: 0.8550\n",
      "Epoch 20/100\n",
      "8000/8000 [==============================] - 1s 67us/sample - loss: 0.3568 - accuracy: 0.8536 - val_loss: 0.3576 - val_accuracy: 0.8560\n",
      "Epoch 21/100\n",
      "8000/8000 [==============================] - 1s 66us/sample - loss: 0.3557 - accuracy: 0.8537 - val_loss: 0.3572 - val_accuracy: 0.8550\n",
      "Epoch 22/100\n",
      "8000/8000 [==============================] - 1s 68us/sample - loss: 0.3546 - accuracy: 0.8540 - val_loss: 0.3568 - val_accuracy: 0.8550\n",
      "Epoch 23/100\n",
      "8000/8000 [==============================] - 1s 66us/sample - loss: 0.3537 - accuracy: 0.8546 - val_loss: 0.3567 - val_accuracy: 0.8550\n",
      "Epoch 24/100\n",
      "8000/8000 [==============================] - 1s 66us/sample - loss: 0.3528 - accuracy: 0.8537 - val_loss: 0.3569 - val_accuracy: 0.8555\n",
      "Epoch 25/100\n",
      "8000/8000 [==============================] - 1s 68us/sample - loss: 0.3516 - accuracy: 0.8540 - val_loss: 0.3574 - val_accuracy: 0.8565\n",
      "Epoch 26/100\n",
      "8000/8000 [==============================] - 1s 68us/sample - loss: 0.3512 - accuracy: 0.8559 - val_loss: 0.3574 - val_accuracy: 0.8530\n",
      "Epoch 27/100\n",
      "8000/8000 [==============================] - 1s 67us/sample - loss: 0.3508 - accuracy: 0.8561 - val_loss: 0.3557 - val_accuracy: 0.8550\n",
      "Epoch 28/100\n",
      "8000/8000 [==============================] - 1s 69us/sample - loss: 0.3497 - accuracy: 0.8553 - val_loss: 0.3562 - val_accuracy: 0.8560\n",
      "Epoch 29/100\n",
      "8000/8000 [==============================] - 1s 64us/sample - loss: 0.3493 - accuracy: 0.8555 - val_loss: 0.3553 - val_accuracy: 0.8540\n",
      "Epoch 30/100\n",
      "8000/8000 [==============================] - 1s 65us/sample - loss: 0.3486 - accuracy: 0.8564 - val_loss: 0.3557 - val_accuracy: 0.8550\n",
      "Epoch 31/100\n",
      "8000/8000 [==============================] - 1s 64us/sample - loss: 0.3482 - accuracy: 0.8572 - val_loss: 0.3554 - val_accuracy: 0.8560\n",
      "Epoch 32/100\n",
      "8000/8000 [==============================] - 1s 64us/sample - loss: 0.3475 - accuracy: 0.8572 - val_loss: 0.3550 - val_accuracy: 0.8565\n",
      "Epoch 33/100\n",
      "8000/8000 [==============================] - 1s 68us/sample - loss: 0.3469 - accuracy: 0.8561 - val_loss: 0.3546 - val_accuracy: 0.8555\n",
      "Epoch 34/100\n",
      "8000/8000 [==============================] - 1s 65us/sample - loss: 0.3460 - accuracy: 0.8572 - val_loss: 0.3544 - val_accuracy: 0.8570\n",
      "Epoch 35/100\n",
      "8000/8000 [==============================] - 1s 69us/sample - loss: 0.3455 - accuracy: 0.8579 - val_loss: 0.3546 - val_accuracy: 0.8535\n",
      "Epoch 36/100\n",
      "8000/8000 [==============================] - 1s 69us/sample - loss: 0.3450 - accuracy: 0.8571 - val_loss: 0.3544 - val_accuracy: 0.8555\n",
      "Epoch 37/100\n",
      "8000/8000 [==============================] - 1s 69us/sample - loss: 0.3444 - accuracy: 0.8575 - val_loss: 0.3540 - val_accuracy: 0.8585\n",
      "Epoch 38/100\n",
      "8000/8000 [==============================] - 1s 67us/sample - loss: 0.3438 - accuracy: 0.8571 - val_loss: 0.3541 - val_accuracy: 0.8560\n",
      "Epoch 39/100\n",
      "8000/8000 [==============================] - 1s 65us/sample - loss: 0.3433 - accuracy: 0.8594 - val_loss: 0.3535 - val_accuracy: 0.8565\n",
      "Epoch 40/100\n",
      "8000/8000 [==============================] - 1s 64us/sample - loss: 0.3429 - accuracy: 0.8579 - val_loss: 0.3537 - val_accuracy: 0.8560\n",
      "Epoch 41/100\n",
      "8000/8000 [==============================] - 1s 69us/sample - loss: 0.3425 - accuracy: 0.8584 - val_loss: 0.3537 - val_accuracy: 0.8560\n",
      "Epoch 42/100\n",
      "8000/8000 [==============================] - 1s 68us/sample - loss: 0.3419 - accuracy: 0.8590 - val_loss: 0.3532 - val_accuracy: 0.8575\n",
      "Epoch 43/100\n",
      "8000/8000 [==============================] - 1s 71us/sample - loss: 0.3414 - accuracy: 0.8596 - val_loss: 0.3529 - val_accuracy: 0.8555\n",
      "Epoch 44/100\n",
      "8000/8000 [==============================] - 1s 77us/sample - loss: 0.3408 - accuracy: 0.8581 - val_loss: 0.3533 - val_accuracy: 0.8565\n",
      "Epoch 45/100\n",
      "8000/8000 [==============================] - 1s 67us/sample - loss: 0.3406 - accuracy: 0.8596 - val_loss: 0.3527 - val_accuracy: 0.8585\n",
      "Epoch 46/100\n",
      "8000/8000 [==============================] - 1s 66us/sample - loss: 0.3398 - accuracy: 0.8596 - val_loss: 0.3528 - val_accuracy: 0.8570\n",
      "Epoch 47/100\n",
      "8000/8000 [==============================] - 1s 69us/sample - loss: 0.3394 - accuracy: 0.8604 - val_loss: 0.3530 - val_accuracy: 0.8550\n",
      "Epoch 48/100\n",
      "8000/8000 [==============================] - 1s 69us/sample - loss: 0.3393 - accuracy: 0.8604 - val_loss: 0.3514 - val_accuracy: 0.8595\n",
      "Epoch 49/100\n",
      "8000/8000 [==============================] - 1s 70us/sample - loss: 0.3385 - accuracy: 0.8589 - val_loss: 0.3507 - val_accuracy: 0.8565\n",
      "Epoch 50/100\n",
      "8000/8000 [==============================] - 1s 69us/sample - loss: 0.3384 - accuracy: 0.8606 - val_loss: 0.3506 - val_accuracy: 0.8555\n",
      "Epoch 51/100\n",
      "8000/8000 [==============================] - 1s 69us/sample - loss: 0.3378 - accuracy: 0.8605 - val_loss: 0.3514 - val_accuracy: 0.8595\n",
      "Epoch 52/100\n",
      "8000/8000 [==============================] - 1s 69us/sample - loss: 0.3377 - accuracy: 0.8608 - val_loss: 0.3506 - val_accuracy: 0.8600\n",
      "Epoch 53/100\n",
      "8000/8000 [==============================] - 1s 68us/sample - loss: 0.3371 - accuracy: 0.8604 - val_loss: 0.3504 - val_accuracy: 0.8585\n",
      "Epoch 54/100\n",
      "8000/8000 [==============================] - 1s 70us/sample - loss: 0.3369 - accuracy: 0.8605 - val_loss: 0.3511 - val_accuracy: 0.8590\n",
      "Epoch 55/100\n",
      "8000/8000 [==============================] - 1s 70us/sample - loss: 0.3365 - accuracy: 0.8609 - val_loss: 0.3499 - val_accuracy: 0.8570\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56/100\n",
      "8000/8000 [==============================] - 1s 68us/sample - loss: 0.3362 - accuracy: 0.8593 - val_loss: 0.3496 - val_accuracy: 0.8590\n",
      "Epoch 57/100\n",
      "8000/8000 [==============================] - 1s 70us/sample - loss: 0.3356 - accuracy: 0.8593 - val_loss: 0.3495 - val_accuracy: 0.8580\n",
      "Epoch 58/100\n",
      "8000/8000 [==============================] - 1s 67us/sample - loss: 0.3354 - accuracy: 0.8615 - val_loss: 0.3489 - val_accuracy: 0.8590\n",
      "Epoch 59/100\n",
      "8000/8000 [==============================] - 1s 71us/sample - loss: 0.3350 - accuracy: 0.8611 - val_loss: 0.3494 - val_accuracy: 0.8600\n",
      "Epoch 60/100\n",
      "8000/8000 [==============================] - 1s 69us/sample - loss: 0.3348 - accuracy: 0.8618 - val_loss: 0.3487 - val_accuracy: 0.8615\n",
      "Epoch 61/100\n",
      "8000/8000 [==============================] - 1s 69us/sample - loss: 0.3343 - accuracy: 0.8608 - val_loss: 0.3506 - val_accuracy: 0.8595\n",
      "Epoch 62/100\n",
      "8000/8000 [==============================] - 1s 68us/sample - loss: 0.3341 - accuracy: 0.8610 - val_loss: 0.3484 - val_accuracy: 0.8615\n",
      "Epoch 63/100\n",
      "8000/8000 [==============================] - 1s 70us/sample - loss: 0.3337 - accuracy: 0.8609 - val_loss: 0.3488 - val_accuracy: 0.8575\n",
      "Epoch 64/100\n",
      "8000/8000 [==============================] - 1s 69us/sample - loss: 0.3338 - accuracy: 0.8608 - val_loss: 0.3483 - val_accuracy: 0.8580\n",
      "Epoch 65/100\n",
      "8000/8000 [==============================] - 1s 71us/sample - loss: 0.3333 - accuracy: 0.8610 - val_loss: 0.3483 - val_accuracy: 0.8595\n",
      "Epoch 66/100\n",
      "8000/8000 [==============================] - 1s 69us/sample - loss: 0.3329 - accuracy: 0.8622 - val_loss: 0.3484 - val_accuracy: 0.8590\n",
      "Epoch 67/100\n",
      "8000/8000 [==============================] - 1s 70us/sample - loss: 0.3326 - accuracy: 0.8620 - val_loss: 0.3486 - val_accuracy: 0.8625\n",
      "Epoch 68/100\n",
      "8000/8000 [==============================] - 1s 70us/sample - loss: 0.3320 - accuracy: 0.8629 - val_loss: 0.3478 - val_accuracy: 0.8580\n",
      "Epoch 69/100\n",
      "8000/8000 [==============================] - 1s 67us/sample - loss: 0.3323 - accuracy: 0.8627 - val_loss: 0.3482 - val_accuracy: 0.8585\n",
      "Epoch 70/100\n",
      "8000/8000 [==============================] - 1s 70us/sample - loss: 0.3319 - accuracy: 0.8641 - val_loss: 0.3475 - val_accuracy: 0.8595\n",
      "Epoch 71/100\n",
      "8000/8000 [==============================] - 1s 69us/sample - loss: 0.3315 - accuracy: 0.8644 - val_loss: 0.3473 - val_accuracy: 0.8640\n",
      "Epoch 72/100\n",
      "8000/8000 [==============================] - 1s 71us/sample - loss: 0.3313 - accuracy: 0.8626 - val_loss: 0.3487 - val_accuracy: 0.8620\n",
      "Epoch 73/100\n",
      "8000/8000 [==============================] - 1s 70us/sample - loss: 0.3307 - accuracy: 0.8630 - val_loss: 0.3477 - val_accuracy: 0.8580\n",
      "Epoch 74/100\n",
      "8000/8000 [==============================] - 1s 70us/sample - loss: 0.3306 - accuracy: 0.8616 - val_loss: 0.3487 - val_accuracy: 0.8595\n",
      "Epoch 75/100\n",
      "8000/8000 [==============================] - 1s 71us/sample - loss: 0.3304 - accuracy: 0.8630 - val_loss: 0.3477 - val_accuracy: 0.8585\n",
      "Epoch 76/100\n",
      "8000/8000 [==============================] - 1s 85us/sample - loss: 0.3300 - accuracy: 0.8639 - val_loss: 0.3469 - val_accuracy: 0.8610\n",
      "Epoch 77/100\n",
      "8000/8000 [==============================] - 1s 73us/sample - loss: 0.3300 - accuracy: 0.8630 - val_loss: 0.3471 - val_accuracy: 0.8615\n",
      "Epoch 78/100\n",
      "8000/8000 [==============================] - 1s 69us/sample - loss: 0.3295 - accuracy: 0.8616 - val_loss: 0.3478 - val_accuracy: 0.8600\n",
      "Epoch 79/100\n",
      "8000/8000 [==============================] - 1s 69us/sample - loss: 0.3293 - accuracy: 0.8641 - val_loss: 0.3461 - val_accuracy: 0.8610\n",
      "Epoch 80/100\n",
      "8000/8000 [==============================] - 1s 70us/sample - loss: 0.3292 - accuracy: 0.8625 - val_loss: 0.3461 - val_accuracy: 0.8605\n",
      "Epoch 81/100\n",
      "8000/8000 [==============================] - 1s 69us/sample - loss: 0.3291 - accuracy: 0.8631 - val_loss: 0.3466 - val_accuracy: 0.8595\n",
      "Epoch 82/100\n",
      "8000/8000 [==============================] - 1s 71us/sample - loss: 0.3289 - accuracy: 0.8634 - val_loss: 0.3464 - val_accuracy: 0.8600\n",
      "Epoch 83/100\n",
      "8000/8000 [==============================] - 1s 73us/sample - loss: 0.3287 - accuracy: 0.8626 - val_loss: 0.3463 - val_accuracy: 0.8585\n",
      "Epoch 84/100\n",
      "8000/8000 [==============================] - 1s 76us/sample - loss: 0.3283 - accuracy: 0.8631 - val_loss: 0.3464 - val_accuracy: 0.8605\n",
      "Epoch 85/100\n",
      "8000/8000 [==============================] - 1s 70us/sample - loss: 0.3282 - accuracy: 0.8639 - val_loss: 0.3458 - val_accuracy: 0.8610\n",
      "Epoch 86/100\n",
      "8000/8000 [==============================] - 1s 72us/sample - loss: 0.3277 - accuracy: 0.8634 - val_loss: 0.3454 - val_accuracy: 0.8610\n",
      "Epoch 87/100\n",
      "8000/8000 [==============================] - 1s 73us/sample - loss: 0.3278 - accuracy: 0.8634 - val_loss: 0.3461 - val_accuracy: 0.8615\n",
      "Epoch 88/100\n",
      "8000/8000 [==============================] - 1s 73us/sample - loss: 0.3271 - accuracy: 0.8637 - val_loss: 0.3456 - val_accuracy: 0.8605\n",
      "Epoch 89/100\n",
      "8000/8000 [==============================] - 1s 70us/sample - loss: 0.3276 - accuracy: 0.8637 - val_loss: 0.3456 - val_accuracy: 0.8615\n",
      "Epoch 90/100\n",
      "8000/8000 [==============================] - 1s 71us/sample - loss: 0.3273 - accuracy: 0.8629 - val_loss: 0.3459 - val_accuracy: 0.8595\n",
      "Epoch 91/100\n",
      "8000/8000 [==============================] - 1s 71us/sample - loss: 0.3269 - accuracy: 0.8631 - val_loss: 0.3457 - val_accuracy: 0.8605\n",
      "Epoch 92/100\n",
      "8000/8000 [==============================] - 1s 71us/sample - loss: 0.3267 - accuracy: 0.8641 - val_loss: 0.3457 - val_accuracy: 0.8625\n",
      "Epoch 93/100\n",
      "8000/8000 [==============================] - 1s 71us/sample - loss: 0.3266 - accuracy: 0.8634 - val_loss: 0.3463 - val_accuracy: 0.8610\n",
      "Epoch 94/100\n",
      "8000/8000 [==============================] - 1s 75us/sample - loss: 0.3262 - accuracy: 0.8630 - val_loss: 0.3461 - val_accuracy: 0.8600\n",
      "Epoch 95/100\n",
      "8000/8000 [==============================] - 1s 73us/sample - loss: 0.3264 - accuracy: 0.8625 - val_loss: 0.3454 - val_accuracy: 0.8630\n",
      "Epoch 96/100\n",
      "8000/8000 [==============================] - 1s 75us/sample - loss: 0.3261 - accuracy: 0.8643 - val_loss: 0.3456 - val_accuracy: 0.8610\n",
      "Epoch 97/100\n",
      "8000/8000 [==============================] - 1s 73us/sample - loss: 0.3261 - accuracy: 0.8641 - val_loss: 0.3452 - val_accuracy: 0.8575\n",
      "Epoch 98/100\n",
      "8000/8000 [==============================] - 1s 69us/sample - loss: 0.3256 - accuracy: 0.8630 - val_loss: 0.3456 - val_accuracy: 0.8595\n",
      "Epoch 99/100\n",
      "8000/8000 [==============================] - 1s 73us/sample - loss: 0.3257 - accuracy: 0.8635 - val_loss: 0.3450 - val_accuracy: 0.8605\n",
      "Epoch 100/100\n",
      "8000/8000 [==============================] - 1s 72us/sample - loss: 0.3256 - accuracy: 0.8645 - val_loss: 0.3455 - val_accuracy: 0.8635\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1a48db5400>"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=100, validation_data=(X_test,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hSUgMq3m0bG7"
   },
   "source": [
    "### Compare the prediction with actual label\n",
    "- Print the same row as done in the previous step but of actual labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "K5WbwVPyz-qQ"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0]])"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[0:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "2000/1 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 37us/sample - loss: 0.2310 - accuracy: 0.8635\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.34554733192920684, 0.8635]\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X_test, y_test,verbose=1)\n",
    "\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2000, 2)\n",
      "[[1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1531,   56],\n",
       "       [ 217,  196]])"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "y_pred = np.round(model.predict(X_test))\n",
    "y_pred[0:10]\n",
    "print(y_pred.shape)\n",
    "print(y_pred[0:10])\n",
    "cm = metrics.confusion_matrix(y_test.argmax(axis=1), y_pred.argmax(axis=1))\n",
    "cm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid SearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "  model_2 = tf.keras.Sequential()\n",
    "  model_2.add(Dense(20, activation='relu', input_shape=(10,)))\n",
    "  model_2.add(Dense(30, activation='relu'))\n",
    "  model_2.add(Dense(20, activation='relu'))\n",
    "  model_2.add(Dense(2, activation='softmax'))\n",
    "  model_2.compile(optimizer='sgd', loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "  return model_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
    "#from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# param = {'n_estimators': [10,50,100,200,500], \n",
    "#          'max_features': [2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22],\n",
    "#          }\n",
    "\n",
    "model_KC = KerasClassifier(build_fn=create_model)\n",
    "\n",
    "optimizers = ['rmsprop', 'adam']\n",
    "init = ['glorot_uniform', 'normal', 'uniform']\n",
    "batches = [100,1000]\n",
    "epochs = [1,10,50]\n",
    "n_estimators = [10,50,100,200,500]\n",
    "max_features = [2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22]\n",
    "param_grid = dict(epochs=epochs, batch_size=batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6400 samples\n",
      "6400/6400 [==============================] - 1s 92us/sample - loss: 0.6191 - accuracy: 0.6938\n",
      "Train on 6400 samples\n",
      "6400/6400 [==============================] - 1s 95us/sample - loss: 0.5645 - accuracy: 0.7937\n",
      "Train on 6400 samples\n",
      "6400/6400 [==============================] - 1s 95us/sample - loss: 0.6342 - accuracy: 0.6680\n",
      "Train on 6400 samples\n",
      "6400/6400 [==============================] - 1s 90us/sample - loss: 0.5864 - accuracy: 0.7172\n",
      "Train on 6400 samples\n",
      "6400/6400 [==============================] - 1s 88us/sample - loss: 0.5491 - accuracy: 0.7784\n",
      "Train on 6400 samples\n",
      "Epoch 1/10\n",
      "6400/6400 [==============================] - 1s 89us/sample - loss: 0.5531 - accuracy: 0.7819\n",
      "Epoch 2/10\n",
      "6400/6400 [==============================] - 0s 19us/sample - loss: 0.5000 - accuracy: 0.7944\n",
      "Epoch 3/10\n",
      "6400/6400 [==============================] - 0s 19us/sample - loss: 0.4809 - accuracy: 0.7945\n",
      "Epoch 4/10\n",
      "6400/6400 [==============================] - 0s 19us/sample - loss: 0.4687 - accuracy: 0.7948\n",
      "Epoch 5/10\n",
      "6400/6400 [==============================] - 0s 19us/sample - loss: 0.4594 - accuracy: 0.7978\n",
      "Epoch 6/10\n",
      "6400/6400 [==============================] - 0s 19us/sample - loss: 0.4521 - accuracy: 0.8003\n",
      "Epoch 7/10\n",
      "6400/6400 [==============================] - 0s 19us/sample - loss: 0.4463 - accuracy: 0.8052\n",
      "Epoch 8/10\n",
      "6400/6400 [==============================] - 0s 19us/sample - loss: 0.4416 - accuracy: 0.8078\n",
      "Epoch 9/10\n",
      "6400/6400 [==============================] - 0s 19us/sample - loss: 0.4376 - accuracy: 0.8102\n",
      "Epoch 10/10\n",
      "6400/6400 [==============================] - 0s 19us/sample - loss: 0.4341 - accuracy: 0.8109\n",
      "Train on 6400 samples\n",
      "Epoch 1/10\n",
      "6400/6400 [==============================] - 1s 91us/sample - loss: 0.6663 - accuracy: 0.6253\n",
      "Epoch 2/10\n",
      "6400/6400 [==============================] - 0s 20us/sample - loss: 0.5307 - accuracy: 0.7945\n",
      "Epoch 3/10\n",
      "6400/6400 [==============================] - 0s 19us/sample - loss: 0.5126 - accuracy: 0.7945\n",
      "Epoch 4/10\n",
      "6400/6400 [==============================] - 0s 18us/sample - loss: 0.5061 - accuracy: 0.7945\n",
      "Epoch 5/10\n",
      "6400/6400 [==============================] - 0s 19us/sample - loss: 0.5014 - accuracy: 0.7945\n",
      "Epoch 6/10\n",
      "6400/6400 [==============================] - 0s 19us/sample - loss: 0.4972 - accuracy: 0.7945\n",
      "Epoch 7/10\n",
      "6400/6400 [==============================] - 0s 19us/sample - loss: 0.4932 - accuracy: 0.7945\n",
      "Epoch 8/10\n",
      "6400/6400 [==============================] - 0s 19us/sample - loss: 0.4895 - accuracy: 0.7945\n",
      "Epoch 9/10\n",
      "6400/6400 [==============================] - 0s 19us/sample - loss: 0.4857 - accuracy: 0.7945\n",
      "Epoch 10/10\n",
      "6400/6400 [==============================] - 0s 19us/sample - loss: 0.4821 - accuracy: 0.7945\n",
      "Train on 6400 samples\n",
      "Epoch 1/10\n",
      "6400/6400 [==============================] - 1s 147us/sample - loss: 0.5650 - accuracy: 0.7895\n",
      "Epoch 2/10\n",
      "6400/6400 [==============================] - 0s 19us/sample - loss: 0.5394 - accuracy: 0.7958\n",
      "Epoch 3/10\n",
      "6400/6400 [==============================] - 0s 19us/sample - loss: 0.5243 - accuracy: 0.7956\n",
      "Epoch 4/10\n",
      "6400/6400 [==============================] - 0s 19us/sample - loss: 0.5129 - accuracy: 0.7956\n",
      "Epoch 5/10\n",
      "6400/6400 [==============================] - 0s 20us/sample - loss: 0.5036 - accuracy: 0.7953\n",
      "Epoch 6/10\n",
      "6400/6400 [==============================] - 0s 19us/sample - loss: 0.4956 - accuracy: 0.7948\n",
      "Epoch 7/10\n",
      "6400/6400 [==============================] - 0s 19us/sample - loss: 0.4884 - accuracy: 0.7941\n",
      "Epoch 8/10\n",
      "6400/6400 [==============================] - 0s 19us/sample - loss: 0.4819 - accuracy: 0.7936\n",
      "Epoch 9/10\n",
      "6400/6400 [==============================] - 0s 20us/sample - loss: 0.4758 - accuracy: 0.7934\n",
      "Epoch 10/10\n",
      "6400/6400 [==============================] - 0s 19us/sample - loss: 0.4703 - accuracy: 0.7936\n",
      "Train on 6400 samples\n",
      "Epoch 1/10\n",
      "6400/6400 [==============================] - 1s 94us/sample - loss: 0.7174 - accuracy: 0.5152\n",
      "Epoch 2/10\n",
      "6400/6400 [==============================] - 0s 19us/sample - loss: 0.5796 - accuracy: 0.7920\n",
      "Epoch 3/10\n",
      "6400/6400 [==============================] - 0s 20us/sample - loss: 0.5369 - accuracy: 0.7975\n",
      "Epoch 4/10\n",
      "6400/6400 [==============================] - 0s 20us/sample - loss: 0.5176 - accuracy: 0.7975\n",
      "Epoch 5/10\n",
      "6400/6400 [==============================] - 0s 19us/sample - loss: 0.5076 - accuracy: 0.7975\n",
      "Epoch 6/10\n",
      "6400/6400 [==============================] - 0s 19us/sample - loss: 0.5019 - accuracy: 0.7975\n",
      "Epoch 7/10\n",
      "6400/6400 [==============================] - 0s 20us/sample - loss: 0.4980 - accuracy: 0.7975\n",
      "Epoch 8/10\n",
      "6400/6400 [==============================] - 0s 21us/sample - loss: 0.4950 - accuracy: 0.7975\n",
      "Epoch 9/10\n",
      "6400/6400 [==============================] - 0s 21us/sample - loss: 0.4923 - accuracy: 0.7975\n",
      "Epoch 10/10\n",
      "6400/6400 [==============================] - 0s 19us/sample - loss: 0.4896 - accuracy: 0.7975\n",
      "Train on 6400 samples\n",
      "Epoch 1/10\n",
      "6400/6400 [==============================] - 1s 93us/sample - loss: 0.5795 - accuracy: 0.7544\n",
      "Epoch 2/10\n",
      "6400/6400 [==============================] - 0s 20us/sample - loss: 0.5126 - accuracy: 0.8028\n",
      "Epoch 3/10\n",
      "6400/6400 [==============================] - 0s 19us/sample - loss: 0.4995 - accuracy: 0.8028\n",
      "Epoch 4/10\n",
      "6400/6400 [==============================] - 0s 19us/sample - loss: 0.4902 - accuracy: 0.8028\n",
      "Epoch 5/10\n",
      "6400/6400 [==============================] - 0s 19us/sample - loss: 0.4824 - accuracy: 0.8028\n",
      "Epoch 6/10\n",
      "6400/6400 [==============================] - 0s 19us/sample - loss: 0.4756 - accuracy: 0.8025\n",
      "Epoch 7/10\n",
      "6400/6400 [==============================] - 0s 20us/sample - loss: 0.4696 - accuracy: 0.8022\n",
      "Epoch 8/10\n",
      "6400/6400 [==============================] - 0s 19us/sample - loss: 0.4644 - accuracy: 0.8012\n",
      "Epoch 9/10\n",
      "6400/6400 [==============================] - 0s 19us/sample - loss: 0.4598 - accuracy: 0.8017\n",
      "Epoch 10/10\n",
      "6400/6400 [==============================] - 0s 19us/sample - loss: 0.4556 - accuracy: 0.8019\n",
      "Train on 6400 samples\n",
      "Epoch 1/50\n",
      "6400/6400 [==============================] - 1s 89us/sample - loss: 0.5695 - accuracy: 0.7541\n",
      "Epoch 2/50\n",
      "6400/6400 [==============================] - 0s 20us/sample - loss: 0.5072 - accuracy: 0.7947\n",
      "Epoch 3/50\n",
      "6400/6400 [==============================] - 0s 20us/sample - loss: 0.4959 - accuracy: 0.7947\n",
      "Epoch 4/50\n",
      "6400/6400 [==============================] - 0s 19us/sample - loss: 0.4880 - accuracy: 0.7945\n",
      "Epoch 5/50\n",
      "6400/6400 [==============================] - 0s 20us/sample - loss: 0.4812 - accuracy: 0.7945\n",
      "Epoch 6/50\n",
      "6400/6400 [==============================] - 0s 20us/sample - loss: 0.4752 - accuracy: 0.7945\n",
      "Epoch 7/50\n",
      "6400/6400 [==============================] - 0s 19us/sample - loss: 0.4700 - accuracy: 0.7956\n",
      "Epoch 8/50\n",
      "6400/6400 [==============================] - 0s 19us/sample - loss: 0.4651 - accuracy: 0.7961\n",
      "Epoch 9/50\n",
      "6400/6400 [==============================] - 0s 20us/sample - loss: 0.4607 - accuracy: 0.7981\n",
      "Epoch 10/50\n",
      "6400/6400 [==============================] - 0s 22us/sample - loss: 0.4567 - accuracy: 0.7995\n",
      "Epoch 11/50\n",
      "6400/6400 [==============================] - 0s 20us/sample - loss: 0.4529 - accuracy: 0.8000\n",
      "Epoch 12/50\n",
      "6400/6400 [==============================] - 0s 20us/sample - loss: 0.4493 - accuracy: 0.8022\n",
      "Epoch 13/50\n",
      "6400/6400 [==============================] - 0s 20us/sample - loss: 0.4458 - accuracy: 0.8053\n",
      "Epoch 14/50\n",
      "6400/6400 [==============================] - 0s 19us/sample - loss: 0.4425 - accuracy: 0.8077\n",
      "Epoch 15/50\n",
      "6400/6400 [==============================] - 0s 19us/sample - loss: 0.4395 - accuracy: 0.8089\n",
      "Epoch 16/50\n",
      "6400/6400 [==============================] - 0s 19us/sample - loss: 0.4365 - accuracy: 0.8111\n",
      "Epoch 17/50\n",
      "6400/6400 [==============================] - 0s 19us/sample - loss: 0.4337 - accuracy: 0.8133\n",
      "Epoch 18/50\n",
      "6400/6400 [==============================] - 0s 21us/sample - loss: 0.4309 - accuracy: 0.8145\n",
      "Epoch 19/50\n",
      "6400/6400 [==============================] - 0s 21us/sample - loss: 0.4283 - accuracy: 0.8153\n",
      "Epoch 20/50\n",
      "6400/6400 [==============================] - 0s 20us/sample - loss: 0.4259 - accuracy: 0.8181\n",
      "Epoch 21/50\n",
      "6400/6400 [==============================] - 0s 19us/sample - loss: 0.4236 - accuracy: 0.8197\n",
      "Epoch 22/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6400/6400 [==============================] - 0s 19us/sample - loss: 0.4213 - accuracy: 0.8203\n",
      "Epoch 23/50\n",
      "6400/6400 [==============================] - 0s 19us/sample - loss: 0.4191 - accuracy: 0.8202\n",
      "Epoch 24/50\n",
      "6400/6400 [==============================] - 0s 19us/sample - loss: 0.4170 - accuracy: 0.8214\n",
      "Epoch 25/50\n",
      "6400/6400 [==============================] - 0s 19us/sample - loss: 0.4149 - accuracy: 0.8225\n",
      "Epoch 26/50\n",
      "6400/6400 [==============================] - 0s 19us/sample - loss: 0.4130 - accuracy: 0.8233\n",
      "Epoch 27/50\n",
      "6400/6400 [==============================] - 0s 19us/sample - loss: 0.4109 - accuracy: 0.8230\n",
      "Epoch 28/50\n",
      "6400/6400 [==============================] - 0s 21us/sample - loss: 0.4089 - accuracy: 0.8241\n",
      "Epoch 29/50\n",
      "6400/6400 [==============================] - 0s 20us/sample - loss: 0.4070 - accuracy: 0.8266\n",
      "Epoch 30/50\n",
      "6400/6400 [==============================] - 0s 20us/sample - loss: 0.4051 - accuracy: 0.8270\n",
      "Epoch 31/50\n",
      "6400/6400 [==============================] - 0s 19us/sample - loss: 0.4031 - accuracy: 0.8288\n",
      "Epoch 32/50\n",
      "6400/6400 [==============================] - 0s 20us/sample - loss: 0.4014 - accuracy: 0.8294\n",
      "Epoch 33/50\n",
      "6400/6400 [==============================] - 0s 19us/sample - loss: 0.3995 - accuracy: 0.8295\n",
      "Epoch 34/50\n",
      "6400/6400 [==============================] - 0s 21us/sample - loss: 0.3978 - accuracy: 0.8319\n",
      "Epoch 35/50\n",
      "6400/6400 [==============================] - 0s 20us/sample - loss: 0.3961 - accuracy: 0.8309\n",
      "Epoch 36/50\n",
      "6400/6400 [==============================] - 0s 20us/sample - loss: 0.3943 - accuracy: 0.8336\n",
      "Epoch 37/50\n",
      "6400/6400 [==============================] - 0s 20us/sample - loss: 0.3928 - accuracy: 0.8341\n",
      "Epoch 38/50\n",
      "6400/6400 [==============================] - 0s 20us/sample - loss: 0.3910 - accuracy: 0.8353\n",
      "Epoch 39/50\n",
      "6400/6400 [==============================] - 0s 19us/sample - loss: 0.3893 - accuracy: 0.8350\n",
      "Epoch 40/50\n",
      "6400/6400 [==============================] - 0s 19us/sample - loss: 0.3878 - accuracy: 0.8381\n",
      "Epoch 41/50\n",
      "6400/6400 [==============================] - 0s 19us/sample - loss: 0.3862 - accuracy: 0.8386\n",
      "Epoch 42/50\n",
      "6400/6400 [==============================] - 0s 20us/sample - loss: 0.3847 - accuracy: 0.8389\n",
      "Epoch 43/50\n",
      "6400/6400 [==============================] - 0s 19us/sample - loss: 0.3832 - accuracy: 0.8388\n",
      "Epoch 44/50\n",
      "6400/6400 [==============================] - 0s 19us/sample - loss: 0.3817 - accuracy: 0.8394\n",
      "Epoch 45/50\n",
      "6400/6400 [==============================] - 0s 20us/sample - loss: 0.3803 - accuracy: 0.8409\n",
      "Epoch 46/50\n",
      "6400/6400 [==============================] - 0s 20us/sample - loss: 0.3789 - accuracy: 0.8425\n",
      "Epoch 47/50\n",
      "6400/6400 [==============================] - 0s 20us/sample - loss: 0.3775 - accuracy: 0.8428\n",
      "Epoch 48/50\n",
      "6400/6400 [==============================] - 0s 20us/sample - loss: 0.3761 - accuracy: 0.8434\n",
      "Epoch 49/50\n",
      "6400/6400 [==============================] - 0s 20us/sample - loss: 0.3748 - accuracy: 0.8448\n",
      "Epoch 50/50\n",
      "6400/6400 [==============================] - 0s 19us/sample - loss: 0.3735 - accuracy: 0.8455\n",
      "Train on 6400 samples\n",
      "Epoch 1/50\n",
      "6400/6400 [==============================] - 1s 96us/sample - loss: 0.6238 - accuracy: 0.6898\n",
      "Epoch 2/50\n",
      "6400/6400 [==============================] - 0s 21us/sample - loss: 0.5311 - accuracy: 0.7942\n",
      "Epoch 3/50\n",
      "6400/6400 [==============================] - 0s 22us/sample - loss: 0.5089 - accuracy: 0.7945\n",
      "Epoch 4/50\n",
      "6400/6400 [==============================] - 0s 20us/sample - loss: 0.4998 - accuracy: 0.7945\n",
      "Epoch 5/50\n",
      "6400/6400 [==============================] - 0s 20us/sample - loss: 0.4935 - accuracy: 0.7945\n",
      "Epoch 6/50\n",
      "6400/6400 [==============================] - 0s 20us/sample - loss: 0.4880 - accuracy: 0.7945\n",
      "Epoch 7/50\n",
      "6400/6400 [==============================] - 0s 23us/sample - loss: 0.4829 - accuracy: 0.7945\n",
      "Epoch 8/50\n",
      "6400/6400 [==============================] - 0s 22us/sample - loss: 0.4782 - accuracy: 0.7945\n",
      "Epoch 9/50\n",
      "6400/6400 [==============================] - 0s 21us/sample - loss: 0.4738 - accuracy: 0.7947\n",
      "Epoch 10/50\n",
      "6400/6400 [==============================] - 0s 19us/sample - loss: 0.4696 - accuracy: 0.7945\n",
      "Epoch 11/50\n",
      "6400/6400 [==============================] - 0s 19us/sample - loss: 0.4656 - accuracy: 0.7945\n",
      "Epoch 12/50\n",
      "6400/6400 [==============================] - 0s 19us/sample - loss: 0.4617 - accuracy: 0.7950\n",
      "Epoch 13/50\n",
      "6400/6400 [==============================] - 0s 20us/sample - loss: 0.4580 - accuracy: 0.7955\n",
      "Epoch 14/50\n",
      "6400/6400 [==============================] - 0s 20us/sample - loss: 0.4545 - accuracy: 0.7952\n",
      "Epoch 15/50\n",
      "6400/6400 [==============================] - 0s 19us/sample - loss: 0.4513 - accuracy: 0.7955\n",
      "Epoch 16/50\n",
      "6400/6400 [==============================] - 0s 19us/sample - loss: 0.4482 - accuracy: 0.7969\n",
      "Epoch 17/50\n",
      "6400/6400 [==============================] - 0s 20us/sample - loss: 0.4453 - accuracy: 0.7984\n",
      "Epoch 18/50\n",
      "6400/6400 [==============================] - 0s 19us/sample - loss: 0.4426 - accuracy: 0.8000\n",
      "Epoch 19/50\n",
      "6400/6400 [==============================] - 0s 18us/sample - loss: 0.4399 - accuracy: 0.8019\n",
      "Epoch 20/50\n",
      "6400/6400 [==============================] - 0s 22us/sample - loss: 0.4374 - accuracy: 0.8039\n",
      "Epoch 21/50\n",
      "6400/6400 [==============================] - 0s 21us/sample - loss: 0.4351 - accuracy: 0.8062\n",
      "Epoch 22/50\n",
      "6400/6400 [==============================] - 0s 21us/sample - loss: 0.4328 - accuracy: 0.8073\n",
      "Epoch 23/50\n",
      "6400/6400 [==============================] - 0s 20us/sample - loss: 0.4305 - accuracy: 0.8087\n",
      "Epoch 24/50\n",
      "6400/6400 [==============================] - 0s 20us/sample - loss: 0.4284 - accuracy: 0.8098\n",
      "Epoch 25/50\n",
      "6400/6400 [==============================] - 0s 21us/sample - loss: 0.4263 - accuracy: 0.8117\n",
      "Epoch 26/50\n",
      "6400/6400 [==============================] - 0s 20us/sample - loss: 0.4242 - accuracy: 0.8150\n",
      "Epoch 27/50\n",
      "6400/6400 [==============================] - 0s 19us/sample - loss: 0.4222 - accuracy: 0.8166\n",
      "Epoch 28/50\n",
      "6400/6400 [==============================] - 0s 21us/sample - loss: 0.4201 - accuracy: 0.8192\n",
      "Epoch 29/50\n",
      "6400/6400 [==============================] - 0s 20us/sample - loss: 0.4181 - accuracy: 0.8217\n",
      "Epoch 30/50\n",
      "6400/6400 [==============================] - 0s 21us/sample - loss: 0.4161 - accuracy: 0.8230\n",
      "Epoch 31/50\n",
      "6400/6400 [==============================] - 0s 21us/sample - loss: 0.4141 - accuracy: 0.8247\n",
      "Epoch 32/50\n",
      "6400/6400 [==============================] - 0s 21us/sample - loss: 0.4121 - accuracy: 0.8247\n",
      "Epoch 33/50\n",
      "6400/6400 [==============================] - 0s 22us/sample - loss: 0.4101 - accuracy: 0.8266\n",
      "Epoch 34/50\n",
      "6400/6400 [==============================] - 0s 21us/sample - loss: 0.4081 - accuracy: 0.8288\n",
      "Epoch 35/50\n",
      "6400/6400 [==============================] - 0s 21us/sample - loss: 0.4062 - accuracy: 0.8297\n",
      "Epoch 36/50\n",
      "6400/6400 [==============================] - 0s 20us/sample - loss: 0.4042 - accuracy: 0.8314\n",
      "Epoch 37/50\n",
      "6400/6400 [==============================] - 0s 22us/sample - loss: 0.4023 - accuracy: 0.8311\n",
      "Epoch 38/50\n",
      "6400/6400 [==============================] - 0s 21us/sample - loss: 0.4004 - accuracy: 0.8319\n",
      "Epoch 39/50\n",
      "6400/6400 [==============================] - 0s 21us/sample - loss: 0.3984 - accuracy: 0.8323\n",
      "Epoch 40/50\n",
      "6400/6400 [==============================] - 0s 22us/sample - loss: 0.3965 - accuracy: 0.8328\n",
      "Epoch 41/50\n",
      "6400/6400 [==============================] - 0s 21us/sample - loss: 0.3948 - accuracy: 0.8336\n",
      "Epoch 42/50\n",
      "6400/6400 [==============================] - 0s 21us/sample - loss: 0.3929 - accuracy: 0.8347\n",
      "Epoch 43/50\n",
      "6400/6400 [==============================] - 0s 21us/sample - loss: 0.3911 - accuracy: 0.8350\n",
      "Epoch 44/50\n",
      "6400/6400 [==============================] - 0s 21us/sample - loss: 0.3893 - accuracy: 0.8350\n",
      "Epoch 45/50\n",
      "6400/6400 [==============================] - 0s 20us/sample - loss: 0.3877 - accuracy: 0.8352\n",
      "Epoch 46/50\n",
      "6400/6400 [==============================] - 0s 22us/sample - loss: 0.3862 - accuracy: 0.8367\n",
      "Epoch 47/50\n",
      "6400/6400 [==============================] - 0s 22us/sample - loss: 0.3846 - accuracy: 0.8373\n",
      "Epoch 48/50\n",
      "6400/6400 [==============================] - 0s 21us/sample - loss: 0.3831 - accuracy: 0.8383\n",
      "Epoch 49/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6400/6400 [==============================] - 0s 21us/sample - loss: 0.3816 - accuracy: 0.8392\n",
      "Epoch 50/50\n",
      "6400/6400 [==============================] - 0s 21us/sample - loss: 0.3802 - accuracy: 0.8395\n",
      "Train on 6400 samples\n",
      "Epoch 1/50\n",
      "6400/6400 [==============================] - 1s 98us/sample - loss: 0.5565 - accuracy: 0.7948\n",
      "Epoch 2/50\n",
      "6400/6400 [==============================] - 0s 22us/sample - loss: 0.5212 - accuracy: 0.7958\n",
      "Epoch 3/50\n",
      "6400/6400 [==============================] - 0s 22us/sample - loss: 0.5108 - accuracy: 0.7958\n",
      "Epoch 4/50\n",
      "6400/6400 [==============================] - 0s 22us/sample - loss: 0.5048 - accuracy: 0.7958\n",
      "Epoch 5/50\n",
      "6400/6400 [==============================] - 0s 21us/sample - loss: 0.4998 - accuracy: 0.7958\n",
      "Epoch 6/50\n",
      "6400/6400 [==============================] - 0s 21us/sample - loss: 0.4954 - accuracy: 0.7958\n",
      "Epoch 7/50\n",
      "6400/6400 [==============================] - 0s 22us/sample - loss: 0.4912 - accuracy: 0.7958\n",
      "Epoch 8/50\n",
      "6400/6400 [==============================] - 0s 21us/sample - loss: 0.4874 - accuracy: 0.7958\n",
      "Epoch 9/50\n",
      "6400/6400 [==============================] - 0s 21us/sample - loss: 0.4837 - accuracy: 0.7958\n",
      "Epoch 10/50\n",
      "6400/6400 [==============================] - 0s 20us/sample - loss: 0.4802 - accuracy: 0.7958\n",
      "Epoch 11/50\n",
      "6400/6400 [==============================] - 0s 22us/sample - loss: 0.4769 - accuracy: 0.7959\n",
      "Epoch 12/50\n",
      "6400/6400 [==============================] - 0s 22us/sample - loss: 0.4737 - accuracy: 0.7959\n",
      "Epoch 13/50\n",
      "6400/6400 [==============================] - 0s 23us/sample - loss: 0.4706 - accuracy: 0.7966\n",
      "Epoch 14/50\n",
      "6400/6400 [==============================] - 0s 22us/sample - loss: 0.4676 - accuracy: 0.7981\n",
      "Epoch 15/50\n",
      "6400/6400 [==============================] - 0s 21us/sample - loss: 0.4648 - accuracy: 0.7994\n",
      "Epoch 16/50\n",
      "6400/6400 [==============================] - 0s 23us/sample - loss: 0.4620 - accuracy: 0.7997\n",
      "Epoch 17/50\n",
      "6400/6400 [==============================] - 0s 21us/sample - loss: 0.4593 - accuracy: 0.8008\n",
      "Epoch 18/50\n",
      "6400/6400 [==============================] - 0s 21us/sample - loss: 0.4567 - accuracy: 0.8012\n",
      "Epoch 19/50\n",
      "6400/6400 [==============================] - 0s 21us/sample - loss: 0.4542 - accuracy: 0.8023\n",
      "Epoch 20/50\n",
      "6400/6400 [==============================] - 0s 23us/sample - loss: 0.4518 - accuracy: 0.8030\n",
      "Epoch 21/50\n",
      "6400/6400 [==============================] - 0s 21us/sample - loss: 0.4495 - accuracy: 0.8045\n",
      "Epoch 22/50\n",
      "6400/6400 [==============================] - 0s 22us/sample - loss: 0.4472 - accuracy: 0.8045\n",
      "Epoch 23/50\n",
      "6400/6400 [==============================] - 0s 25us/sample - loss: 0.4450 - accuracy: 0.8052\n",
      "Epoch 24/50\n",
      "6400/6400 [==============================] - 0s 23us/sample - loss: 0.4430 - accuracy: 0.8061\n",
      "Epoch 25/50\n",
      "6400/6400 [==============================] - 0s 21us/sample - loss: 0.4409 - accuracy: 0.8056\n",
      "Epoch 26/50\n",
      "6400/6400 [==============================] - 0s 22us/sample - loss: 0.4390 - accuracy: 0.8058\n",
      "Epoch 27/50\n",
      "6400/6400 [==============================] - 0s 22us/sample - loss: 0.4371 - accuracy: 0.8061\n",
      "Epoch 28/50\n",
      "6400/6400 [==============================] - 0s 22us/sample - loss: 0.4353 - accuracy: 0.8064\n",
      "Epoch 29/50\n",
      "6400/6400 [==============================] - 0s 22us/sample - loss: 0.4337 - accuracy: 0.8080\n",
      "Epoch 30/50\n",
      "6400/6400 [==============================] - 0s 22us/sample - loss: 0.4321 - accuracy: 0.8092\n",
      "Epoch 31/50\n",
      "6400/6400 [==============================] - 0s 22us/sample - loss: 0.4305 - accuracy: 0.8098\n",
      "Epoch 32/50\n",
      "6400/6400 [==============================] - 0s 24us/sample - loss: 0.4290 - accuracy: 0.8120\n",
      "Epoch 33/50\n",
      "6400/6400 [==============================] - 0s 22us/sample - loss: 0.4277 - accuracy: 0.8128\n",
      "Epoch 34/50\n",
      "6400/6400 [==============================] - 0s 23us/sample - loss: 0.4263 - accuracy: 0.8133\n",
      "Epoch 35/50\n",
      "6400/6400 [==============================] - 0s 22us/sample - loss: 0.4250 - accuracy: 0.8142\n",
      "Epoch 36/50\n",
      "6400/6400 [==============================] - 0s 22us/sample - loss: 0.4239 - accuracy: 0.8136\n",
      "Epoch 37/50\n",
      "6400/6400 [==============================] - 0s 24us/sample - loss: 0.4227 - accuracy: 0.8148\n",
      "Epoch 38/50\n",
      "6400/6400 [==============================] - 0s 21us/sample - loss: 0.4215 - accuracy: 0.8161\n",
      "Epoch 39/50\n",
      "6400/6400 [==============================] - 0s 23us/sample - loss: 0.4202 - accuracy: 0.8166\n",
      "Epoch 40/50\n",
      "6400/6400 [==============================] - 0s 22us/sample - loss: 0.4192 - accuracy: 0.8173\n",
      "Epoch 41/50\n",
      "6400/6400 [==============================] - 0s 22us/sample - loss: 0.4180 - accuracy: 0.8189\n",
      "Epoch 42/50\n",
      "6400/6400 [==============================] - 0s 22us/sample - loss: 0.4169 - accuracy: 0.8195\n",
      "Epoch 43/50\n",
      "6400/6400 [==============================] - 0s 22us/sample - loss: 0.4158 - accuracy: 0.8195\n",
      "Epoch 44/50\n",
      "6400/6400 [==============================] - 0s 23us/sample - loss: 0.4147 - accuracy: 0.8197\n",
      "Epoch 45/50\n",
      "6400/6400 [==============================] - 0s 21us/sample - loss: 0.4136 - accuracy: 0.8213\n",
      "Epoch 46/50\n",
      "6400/6400 [==============================] - 0s 24us/sample - loss: 0.4125 - accuracy: 0.8222\n",
      "Epoch 47/50\n",
      "6400/6400 [==============================] - 0s 21us/sample - loss: 0.4112 - accuracy: 0.8236\n",
      "Epoch 48/50\n",
      "6400/6400 [==============================] - 0s 22us/sample - loss: 0.4101 - accuracy: 0.8225\n",
      "Epoch 49/50\n",
      "6400/6400 [==============================] - 0s 21us/sample - loss: 0.4088 - accuracy: 0.8242\n",
      "Epoch 50/50\n",
      "6400/6400 [==============================] - 0s 22us/sample - loss: 0.4077 - accuracy: 0.8250\n",
      "Train on 6400 samples\n",
      "Epoch 1/50\n",
      "6400/6400 [==============================] - 1s 102us/sample - loss: 0.5531 - accuracy: 0.7800\n",
      "Epoch 2/50\n",
      "6400/6400 [==============================] - 0s 21us/sample - loss: 0.5096 - accuracy: 0.7972\n",
      "Epoch 3/50\n",
      "6400/6400 [==============================] - 0s 21us/sample - loss: 0.4971 - accuracy: 0.7973\n",
      "Epoch 4/50\n",
      "6400/6400 [==============================] - 0s 21us/sample - loss: 0.4878 - accuracy: 0.7975\n",
      "Epoch 5/50\n",
      "6400/6400 [==============================] - 0s 22us/sample - loss: 0.4801 - accuracy: 0.7973\n",
      "Epoch 6/50\n",
      "6400/6400 [==============================] - 0s 22us/sample - loss: 0.4735 - accuracy: 0.7977\n",
      "Epoch 7/50\n",
      "6400/6400 [==============================] - 0s 23us/sample - loss: 0.4679 - accuracy: 0.7980\n",
      "Epoch 8/50\n",
      "6400/6400 [==============================] - 0s 20us/sample - loss: 0.4629 - accuracy: 0.7994\n",
      "Epoch 9/50\n",
      "6400/6400 [==============================] - 0s 22us/sample - loss: 0.4585 - accuracy: 0.7998\n",
      "Epoch 10/50\n",
      "6400/6400 [==============================] - 0s 23us/sample - loss: 0.4545 - accuracy: 0.8002\n",
      "Epoch 11/50\n",
      "6400/6400 [==============================] - 0s 22us/sample - loss: 0.4511 - accuracy: 0.8002\n",
      "Epoch 12/50\n",
      "6400/6400 [==============================] - 0s 22us/sample - loss: 0.4478 - accuracy: 0.8008\n",
      "Epoch 13/50\n",
      "6400/6400 [==============================] - 0s 21us/sample - loss: 0.4451 - accuracy: 0.8009\n",
      "Epoch 14/50\n",
      "6400/6400 [==============================] - 0s 25us/sample - loss: 0.4424 - accuracy: 0.8022\n",
      "Epoch 15/50\n",
      "6400/6400 [==============================] - 0s 24us/sample - loss: 0.4402 - accuracy: 0.8042\n",
      "Epoch 16/50\n",
      "6400/6400 [==============================] - 0s 23us/sample - loss: 0.4381 - accuracy: 0.8047\n",
      "Epoch 17/50\n",
      "6400/6400 [==============================] - 0s 23us/sample - loss: 0.4360 - accuracy: 0.8062\n",
      "Epoch 18/50\n",
      "6400/6400 [==============================] - 0s 23us/sample - loss: 0.4341 - accuracy: 0.8078\n",
      "Epoch 19/50\n",
      "6400/6400 [==============================] - 0s 21us/sample - loss: 0.4323 - accuracy: 0.8081\n",
      "Epoch 20/50\n",
      "6400/6400 [==============================] - 0s 22us/sample - loss: 0.4307 - accuracy: 0.8097\n",
      "Epoch 21/50\n",
      "6400/6400 [==============================] - 0s 24us/sample - loss: 0.4290 - accuracy: 0.8114\n",
      "Epoch 22/50\n",
      "6400/6400 [==============================] - 0s 23us/sample - loss: 0.4275 - accuracy: 0.8117\n",
      "Epoch 23/50\n",
      "6400/6400 [==============================] - 0s 22us/sample - loss: 0.4260 - accuracy: 0.8138\n",
      "Epoch 24/50\n",
      "6400/6400 [==============================] - 0s 21us/sample - loss: 0.4245 - accuracy: 0.8141\n",
      "Epoch 25/50\n",
      "6400/6400 [==============================] - 0s 21us/sample - loss: 0.4229 - accuracy: 0.8158\n",
      "Epoch 26/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6400/6400 [==============================] - 0s 23us/sample - loss: 0.4215 - accuracy: 0.8172\n",
      "Epoch 27/50\n",
      "6400/6400 [==============================] - 0s 22us/sample - loss: 0.4201 - accuracy: 0.8173\n",
      "Epoch 28/50\n",
      "6400/6400 [==============================] - 0s 22us/sample - loss: 0.4186 - accuracy: 0.8189\n",
      "Epoch 29/50\n",
      "6400/6400 [==============================] - 0s 22us/sample - loss: 0.4173 - accuracy: 0.8197\n",
      "Epoch 30/50\n",
      "6400/6400 [==============================] - 0s 22us/sample - loss: 0.4159 - accuracy: 0.8203\n",
      "Epoch 31/50\n",
      "6400/6400 [==============================] - 0s 22us/sample - loss: 0.4145 - accuracy: 0.8217\n",
      "Epoch 32/50\n",
      "6400/6400 [==============================] - 0s 23us/sample - loss: 0.4132 - accuracy: 0.8227\n",
      "Epoch 33/50\n",
      "6400/6400 [==============================] - 0s 22us/sample - loss: 0.4120 - accuracy: 0.8253\n",
      "Epoch 34/50\n",
      "6400/6400 [==============================] - 0s 23us/sample - loss: 0.4106 - accuracy: 0.8253\n",
      "Epoch 35/50\n",
      "6400/6400 [==============================] - 0s 22us/sample - loss: 0.4094 - accuracy: 0.8273\n",
      "Epoch 36/50\n",
      "6400/6400 [==============================] - 0s 23us/sample - loss: 0.4081 - accuracy: 0.8281\n",
      "Epoch 37/50\n",
      "6400/6400 [==============================] - 0s 22us/sample - loss: 0.4068 - accuracy: 0.8297\n",
      "Epoch 38/50\n",
      "6400/6400 [==============================] - 0s 23us/sample - loss: 0.4055 - accuracy: 0.8294\n",
      "Epoch 39/50\n",
      "6400/6400 [==============================] - 0s 22us/sample - loss: 0.4041 - accuracy: 0.8306\n",
      "Epoch 40/50\n",
      "6400/6400 [==============================] - 0s 22us/sample - loss: 0.4028 - accuracy: 0.8320\n",
      "Epoch 41/50\n",
      "6400/6400 [==============================] - 0s 24us/sample - loss: 0.4016 - accuracy: 0.8311\n",
      "Epoch 42/50\n",
      "6400/6400 [==============================] - 0s 23us/sample - loss: 0.4003 - accuracy: 0.8327\n",
      "Epoch 43/50\n",
      "6400/6400 [==============================] - 0s 22us/sample - loss: 0.3989 - accuracy: 0.8345\n",
      "Epoch 44/50\n",
      "6400/6400 [==============================] - 0s 23us/sample - loss: 0.3976 - accuracy: 0.8347\n",
      "Epoch 45/50\n",
      "6400/6400 [==============================] - 0s 22us/sample - loss: 0.3964 - accuracy: 0.8358\n",
      "Epoch 46/50\n",
      "6400/6400 [==============================] - 0s 23us/sample - loss: 0.3951 - accuracy: 0.8366\n",
      "Epoch 47/50\n",
      "6400/6400 [==============================] - 0s 22us/sample - loss: 0.3939 - accuracy: 0.8364\n",
      "Epoch 48/50\n",
      "6400/6400 [==============================] - 0s 22us/sample - loss: 0.3925 - accuracy: 0.8380\n",
      "Epoch 49/50\n",
      "6400/6400 [==============================] - 0s 23us/sample - loss: 0.3911 - accuracy: 0.8383\n",
      "Epoch 50/50\n",
      "6400/6400 [==============================] - 0s 22us/sample - loss: 0.3899 - accuracy: 0.8397\n",
      "Train on 6400 samples\n",
      "Epoch 1/50\n",
      "6400/6400 [==============================] - 1s 162us/sample - loss: 0.5998 - accuracy: 0.6931\n",
      "Epoch 2/50\n",
      "6400/6400 [==============================] - 0s 21us/sample - loss: 0.4929 - accuracy: 0.8028\n",
      "Epoch 3/50\n",
      "6400/6400 [==============================] - 0s 21us/sample - loss: 0.4805 - accuracy: 0.8028\n",
      "Epoch 4/50\n",
      "6400/6400 [==============================] - 0s 22us/sample - loss: 0.4728 - accuracy: 0.8028\n",
      "Epoch 5/50\n",
      "6400/6400 [==============================] - 0s 21us/sample - loss: 0.4665 - accuracy: 0.8028\n",
      "Epoch 6/50\n",
      "6400/6400 [==============================] - 0s 22us/sample - loss: 0.4611 - accuracy: 0.8028\n",
      "Epoch 7/50\n",
      "6400/6400 [==============================] - 0s 23us/sample - loss: 0.4561 - accuracy: 0.8030\n",
      "Epoch 8/50\n",
      "6400/6400 [==============================] - 0s 23us/sample - loss: 0.4516 - accuracy: 0.8031\n",
      "Epoch 9/50\n",
      "6400/6400 [==============================] - 0s 22us/sample - loss: 0.4474 - accuracy: 0.8033\n",
      "Epoch 10/50\n",
      "6400/6400 [==============================] - 0s 22us/sample - loss: 0.4436 - accuracy: 0.8036\n",
      "Epoch 11/50\n",
      "6400/6400 [==============================] - 0s 22us/sample - loss: 0.4402 - accuracy: 0.8039\n",
      "Epoch 12/50\n",
      "6400/6400 [==============================] - 0s 22us/sample - loss: 0.4370 - accuracy: 0.8047\n",
      "Epoch 13/50\n",
      "6400/6400 [==============================] - 0s 22us/sample - loss: 0.4342 - accuracy: 0.8047\n",
      "Epoch 14/50\n",
      "6400/6400 [==============================] - 0s 22us/sample - loss: 0.4314 - accuracy: 0.8075\n",
      "Epoch 15/50\n",
      "6400/6400 [==============================] - 0s 21us/sample - loss: 0.4290 - accuracy: 0.8087\n",
      "Epoch 16/50\n",
      "6400/6400 [==============================] - 0s 21us/sample - loss: 0.4268 - accuracy: 0.8092\n",
      "Epoch 17/50\n",
      "6400/6400 [==============================] - 0s 22us/sample - loss: 0.4246 - accuracy: 0.8102\n",
      "Epoch 18/50\n",
      "6400/6400 [==============================] - 0s 23us/sample - loss: 0.4225 - accuracy: 0.8112\n",
      "Epoch 19/50\n",
      "6400/6400 [==============================] - 0s 24us/sample - loss: 0.4205 - accuracy: 0.8116\n",
      "Epoch 20/50\n",
      "6400/6400 [==============================] - 0s 22us/sample - loss: 0.4186 - accuracy: 0.8138\n",
      "Epoch 21/50\n",
      "6400/6400 [==============================] - 0s 22us/sample - loss: 0.4167 - accuracy: 0.8139\n",
      "Epoch 22/50\n",
      "6400/6400 [==============================] - 0s 21us/sample - loss: 0.4149 - accuracy: 0.8150\n",
      "Epoch 23/50\n",
      "6400/6400 [==============================] - 0s 22us/sample - loss: 0.4131 - accuracy: 0.8172\n",
      "Epoch 24/50\n",
      "6400/6400 [==============================] - 0s 22us/sample - loss: 0.4115 - accuracy: 0.8189\n",
      "Epoch 25/50\n",
      "6400/6400 [==============================] - 0s 24us/sample - loss: 0.4096 - accuracy: 0.8213\n",
      "Epoch 26/50\n",
      "6400/6400 [==============================] - 0s 23us/sample - loss: 0.4079 - accuracy: 0.8241\n",
      "Epoch 27/50\n",
      "6400/6400 [==============================] - 0s 22us/sample - loss: 0.4063 - accuracy: 0.8250\n",
      "Epoch 28/50\n",
      "6400/6400 [==============================] - 0s 22us/sample - loss: 0.4046 - accuracy: 0.8278\n",
      "Epoch 29/50\n",
      "6400/6400 [==============================] - 0s 22us/sample - loss: 0.4030 - accuracy: 0.8292\n",
      "Epoch 30/50\n",
      "6400/6400 [==============================] - 0s 23us/sample - loss: 0.4014 - accuracy: 0.8278\n",
      "Epoch 31/50\n",
      "6400/6400 [==============================] - 0s 22us/sample - loss: 0.3996 - accuracy: 0.8303\n",
      "Epoch 32/50\n",
      "6400/6400 [==============================] - 0s 23us/sample - loss: 0.3982 - accuracy: 0.8298\n",
      "Epoch 33/50\n",
      "6400/6400 [==============================] - 0s 21us/sample - loss: 0.3966 - accuracy: 0.8320\n",
      "Epoch 34/50\n",
      "6400/6400 [==============================] - 0s 24us/sample - loss: 0.3949 - accuracy: 0.8328\n",
      "Epoch 35/50\n",
      "6400/6400 [==============================] - 0s 24us/sample - loss: 0.3934 - accuracy: 0.8325\n",
      "Epoch 36/50\n",
      "6400/6400 [==============================] - 0s 23us/sample - loss: 0.3917 - accuracy: 0.8345\n",
      "Epoch 37/50\n",
      "6400/6400 [==============================] - 0s 23us/sample - loss: 0.3903 - accuracy: 0.8352\n",
      "Epoch 38/50\n",
      "6400/6400 [==============================] - 0s 23us/sample - loss: 0.3886 - accuracy: 0.8358\n",
      "Epoch 39/50\n",
      "6400/6400 [==============================] - 0s 22us/sample - loss: 0.3874 - accuracy: 0.8366\n",
      "Epoch 40/50\n",
      "6400/6400 [==============================] - 0s 24us/sample - loss: 0.3858 - accuracy: 0.8378\n",
      "Epoch 41/50\n",
      "6400/6400 [==============================] - 0s 23us/sample - loss: 0.3845 - accuracy: 0.8394\n",
      "Epoch 42/50\n",
      "6400/6400 [==============================] - 0s 22us/sample - loss: 0.3831 - accuracy: 0.8394\n",
      "Epoch 43/50\n",
      "6400/6400 [==============================] - 0s 23us/sample - loss: 0.3816 - accuracy: 0.8409\n",
      "Epoch 44/50\n",
      "6400/6400 [==============================] - 0s 24us/sample - loss: 0.3803 - accuracy: 0.8425\n",
      "Epoch 45/50\n",
      "6400/6400 [==============================] - 0s 24us/sample - loss: 0.3789 - accuracy: 0.8425\n",
      "Epoch 46/50\n",
      "6400/6400 [==============================] - 0s 23us/sample - loss: 0.3775 - accuracy: 0.8430\n",
      "Epoch 47/50\n",
      "6400/6400 [==============================] - 0s 21us/sample - loss: 0.3762 - accuracy: 0.8428\n",
      "Epoch 48/50\n",
      "6400/6400 [==============================] - 0s 22us/sample - loss: 0.3747 - accuracy: 0.8444\n",
      "Epoch 49/50\n",
      "6400/6400 [==============================] - 0s 22us/sample - loss: 0.3735 - accuracy: 0.8448\n",
      "Epoch 50/50\n",
      "6400/6400 [==============================] - 0s 22us/sample - loss: 0.3723 - accuracy: 0.8455\n",
      "Train on 6400 samples\n",
      "6400/6400 [==============================] - 1s 91us/sample - loss: 0.7824 - accuracy: 0.3053\n",
      "Train on 6400 samples\n",
      "6400/6400 [==============================] - 1s 92us/sample - loss: 0.6106 - accuracy: 0.6842\n",
      "Train on 6400 samples\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6400/6400 [==============================] - 1s 87us/sample - loss: 0.7665 - accuracy: 0.2977\n",
      "Train on 6400 samples\n",
      "6400/6400 [==============================] - 1s 87us/sample - loss: 0.6024 - accuracy: 0.7403\n",
      "Train on 6400 samples\n",
      "6400/6400 [==============================] - 1s 89us/sample - loss: 0.7438 - accuracy: 0.3903\n",
      "Train on 6400 samples\n",
      "Epoch 1/10\n",
      "6400/6400 [==============================] - 1s 88us/sample - loss: 1.0419 - accuracy: 0.2056\n",
      "Epoch 2/10\n",
      "6400/6400 [==============================] - 0s 7us/sample - loss: 0.9010 - accuracy: 0.2139\n",
      "Epoch 3/10\n",
      "6400/6400 [==============================] - 0s 7us/sample - loss: 0.8069 - accuracy: 0.2577\n",
      "Epoch 4/10\n",
      "6400/6400 [==============================] - 0s 8us/sample - loss: 0.7410 - accuracy: 0.3858\n",
      "Epoch 5/10\n",
      "6400/6400 [==============================] - 0s 7us/sample - loss: 0.6935 - accuracy: 0.5341\n",
      "Epoch 6/10\n",
      "6400/6400 [==============================] - 0s 8us/sample - loss: 0.6577 - accuracy: 0.6556\n",
      "Epoch 7/10\n",
      "6400/6400 [==============================] - 0s 7us/sample - loss: 0.6301 - accuracy: 0.7428\n",
      "Epoch 8/10\n",
      "6400/6400 [==============================] - 0s 8us/sample - loss: 0.6084 - accuracy: 0.7805\n",
      "Epoch 9/10\n",
      "6400/6400 [==============================] - 0s 9us/sample - loss: 0.5910 - accuracy: 0.7916\n",
      "Epoch 10/10\n",
      "6400/6400 [==============================] - 0s 8us/sample - loss: 0.5770 - accuracy: 0.7955\n",
      "Train on 6400 samples\n",
      "Epoch 1/10\n",
      "6400/6400 [==============================] - 1s 88us/sample - loss: 0.7089 - accuracy: 0.4837\n",
      "Epoch 2/10\n",
      "6400/6400 [==============================] - 0s 7us/sample - loss: 0.6576 - accuracy: 0.6506\n",
      "Epoch 3/10\n",
      "6400/6400 [==============================] - 0s 7us/sample - loss: 0.6203 - accuracy: 0.7428\n",
      "Epoch 4/10\n",
      "6400/6400 [==============================] - 0s 7us/sample - loss: 0.5929 - accuracy: 0.7800\n",
      "Epoch 5/10\n",
      "6400/6400 [==============================] - 0s 7us/sample - loss: 0.5730 - accuracy: 0.7947\n",
      "Epoch 6/10\n",
      "6400/6400 [==============================] - 0s 7us/sample - loss: 0.5579 - accuracy: 0.7945\n",
      "Epoch 7/10\n",
      "6400/6400 [==============================] - 0s 7us/sample - loss: 0.5468 - accuracy: 0.7945\n",
      "Epoch 8/10\n",
      "6400/6400 [==============================] - 0s 7us/sample - loss: 0.5383 - accuracy: 0.7945\n",
      "Epoch 9/10\n",
      "6400/6400 [==============================] - 0s 7us/sample - loss: 0.5317 - accuracy: 0.7945\n",
      "Epoch 10/10\n",
      "6400/6400 [==============================] - 0s 7us/sample - loss: 0.5266 - accuracy: 0.7945\n",
      "Train on 6400 samples\n",
      "Epoch 1/10\n",
      "6400/6400 [==============================] - 1s 94us/sample - loss: 0.8639 - accuracy: 0.2406\n",
      "Epoch 2/10\n",
      "6400/6400 [==============================] - 0s 7us/sample - loss: 0.7685 - accuracy: 0.3552\n",
      "Epoch 3/10\n",
      "6400/6400 [==============================] - 0s 8us/sample - loss: 0.7066 - accuracy: 0.5058\n",
      "Epoch 4/10\n",
      "6400/6400 [==============================] - 0s 7us/sample - loss: 0.6641 - accuracy: 0.6286\n",
      "Epoch 5/10\n",
      "6400/6400 [==============================] - 0s 7us/sample - loss: 0.6337 - accuracy: 0.7119\n",
      "Epoch 6/10\n",
      "6400/6400 [==============================] - 0s 7us/sample - loss: 0.6112 - accuracy: 0.7577\n",
      "Epoch 7/10\n",
      "6400/6400 [==============================] - 0s 8us/sample - loss: 0.5943 - accuracy: 0.7734\n",
      "Epoch 8/10\n",
      "6400/6400 [==============================] - 0s 7us/sample - loss: 0.5811 - accuracy: 0.7844\n",
      "Epoch 9/10\n",
      "6400/6400 [==============================] - 0s 7us/sample - loss: 0.5705 - accuracy: 0.7883\n",
      "Epoch 10/10\n",
      "6400/6400 [==============================] - 0s 7us/sample - loss: 0.5620 - accuracy: 0.7912\n",
      "Train on 6400 samples\n",
      "Epoch 1/10\n",
      "6400/6400 [==============================] - 1s 88us/sample - loss: 0.6921 - accuracy: 0.5373\n",
      "Epoch 2/10\n",
      "6400/6400 [==============================] - 0s 7us/sample - loss: 0.6519 - accuracy: 0.6720\n",
      "Epoch 3/10\n",
      "6400/6400 [==============================] - 0s 7us/sample - loss: 0.6223 - accuracy: 0.7478\n",
      "Epoch 4/10\n",
      "6400/6400 [==============================] - 0s 7us/sample - loss: 0.6000 - accuracy: 0.7798\n",
      "Epoch 5/10\n",
      "6400/6400 [==============================] - 0s 7us/sample - loss: 0.5825 - accuracy: 0.7936\n",
      "Epoch 6/10\n",
      "6400/6400 [==============================] - 0s 7us/sample - loss: 0.5688 - accuracy: 0.7981\n",
      "Epoch 7/10\n",
      "6400/6400 [==============================] - 0s 7us/sample - loss: 0.5577 - accuracy: 0.7980\n",
      "Epoch 8/10\n",
      "6400/6400 [==============================] - 0s 7us/sample - loss: 0.5489 - accuracy: 0.7977\n",
      "Epoch 9/10\n",
      "6400/6400 [==============================] - 0s 8us/sample - loss: 0.5415 - accuracy: 0.7975\n",
      "Epoch 10/10\n",
      "6400/6400 [==============================] - 0s 8us/sample - loss: 0.5353 - accuracy: 0.7975\n",
      "Train on 6400 samples\n",
      "Epoch 1/10\n",
      "6400/6400 [==============================] - 1s 89us/sample - loss: 0.5473 - accuracy: 0.7875\n",
      "Epoch 2/10\n",
      "6400/6400 [==============================] - 0s 7us/sample - loss: 0.5372 - accuracy: 0.7936\n",
      "Epoch 3/10\n",
      "6400/6400 [==============================] - 0s 7us/sample - loss: 0.5294 - accuracy: 0.7986\n",
      "Epoch 4/10\n",
      "6400/6400 [==============================] - 0s 7us/sample - loss: 0.5236 - accuracy: 0.8003\n",
      "Epoch 5/10\n",
      "6400/6400 [==============================] - 0s 8us/sample - loss: 0.5188 - accuracy: 0.8016\n",
      "Epoch 6/10\n",
      "6400/6400 [==============================] - 0s 8us/sample - loss: 0.5150 - accuracy: 0.8027\n",
      "Epoch 7/10\n",
      "6400/6400 [==============================] - 0s 7us/sample - loss: 0.5119 - accuracy: 0.8028\n",
      "Epoch 8/10\n",
      "6400/6400 [==============================] - 0s 8us/sample - loss: 0.5095 - accuracy: 0.8028\n",
      "Epoch 9/10\n",
      "6400/6400 [==============================] - 0s 7us/sample - loss: 0.5073 - accuracy: 0.8028\n",
      "Epoch 10/10\n",
      "6400/6400 [==============================] - 0s 8us/sample - loss: 0.5055 - accuracy: 0.8028\n",
      "Train on 6400 samples\n",
      "Epoch 1/50\n",
      "6400/6400 [==============================] - 1s 89us/sample - loss: 0.6208 - accuracy: 0.7781\n",
      "Epoch 2/50\n",
      "6400/6400 [==============================] - 0s 7us/sample - loss: 0.6042 - accuracy: 0.7889\n",
      "Epoch 3/50\n",
      "6400/6400 [==============================] - 0s 7us/sample - loss: 0.5899 - accuracy: 0.7920\n",
      "Epoch 4/50\n",
      "6400/6400 [==============================] - 0s 8us/sample - loss: 0.5780 - accuracy: 0.7934\n",
      "Epoch 5/50\n",
      "6400/6400 [==============================] - 0s 7us/sample - loss: 0.5682 - accuracy: 0.7937\n",
      "Epoch 6/50\n",
      "6400/6400 [==============================] - 0s 7us/sample - loss: 0.5598 - accuracy: 0.7944\n",
      "Epoch 7/50\n",
      "6400/6400 [==============================] - 0s 7us/sample - loss: 0.5525 - accuracy: 0.7944\n",
      "Epoch 8/50\n",
      "6400/6400 [==============================] - 0s 7us/sample - loss: 0.5464 - accuracy: 0.7944\n",
      "Epoch 9/50\n",
      "6400/6400 [==============================] - 0s 7us/sample - loss: 0.5410 - accuracy: 0.7944\n",
      "Epoch 10/50\n",
      "6400/6400 [==============================] - 0s 7us/sample - loss: 0.5363 - accuracy: 0.7944\n",
      "Epoch 11/50\n",
      "6400/6400 [==============================] - 0s 7us/sample - loss: 0.5326 - accuracy: 0.7944\n",
      "Epoch 12/50\n",
      "6400/6400 [==============================] - 0s 7us/sample - loss: 0.5292 - accuracy: 0.7944\n",
      "Epoch 13/50\n",
      "6400/6400 [==============================] - 0s 7us/sample - loss: 0.5263 - accuracy: 0.7944\n",
      "Epoch 14/50\n",
      "6400/6400 [==============================] - 0s 7us/sample - loss: 0.5237 - accuracy: 0.7944\n",
      "Epoch 15/50\n",
      "6400/6400 [==============================] - 0s 7us/sample - loss: 0.5215 - accuracy: 0.7944\n",
      "Epoch 16/50\n",
      "6400/6400 [==============================] - 0s 7us/sample - loss: 0.5195 - accuracy: 0.7944\n",
      "Epoch 17/50\n",
      "6400/6400 [==============================] - 0s 7us/sample - loss: 0.5177 - accuracy: 0.7944\n",
      "Epoch 18/50\n",
      "6400/6400 [==============================] - 0s 8us/sample - loss: 0.5160 - accuracy: 0.7944\n",
      "Epoch 19/50\n",
      "6400/6400 [==============================] - 0s 7us/sample - loss: 0.5144 - accuracy: 0.7944\n",
      "Epoch 20/50\n",
      "6400/6400 [==============================] - 0s 7us/sample - loss: 0.5129 - accuracy: 0.7944\n",
      "Epoch 21/50\n",
      "6400/6400 [==============================] - 0s 7us/sample - loss: 0.5116 - accuracy: 0.7944\n",
      "Epoch 22/50\n",
      "6400/6400 [==============================] - 0s 7us/sample - loss: 0.5103 - accuracy: 0.7944\n",
      "Epoch 23/50\n",
      "6400/6400 [==============================] - 0s 7us/sample - loss: 0.5091 - accuracy: 0.7944\n",
      "Epoch 24/50\n",
      "6400/6400 [==============================] - 0s 7us/sample - loss: 0.5080 - accuracy: 0.7944\n",
      "Epoch 25/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6400/6400 [==============================] - 0s 9us/sample - loss: 0.5069 - accuracy: 0.7944\n",
      "Epoch 26/50\n",
      "6400/6400 [==============================] - 0s 7us/sample - loss: 0.5059 - accuracy: 0.7944\n",
      "Epoch 27/50\n",
      "6400/6400 [==============================] - 0s 7us/sample - loss: 0.5049 - accuracy: 0.7944\n",
      "Epoch 28/50\n",
      "6400/6400 [==============================] - 0s 7us/sample - loss: 0.5039 - accuracy: 0.7944\n",
      "Epoch 29/50\n",
      "6400/6400 [==============================] - 0s 7us/sample - loss: 0.5030 - accuracy: 0.7944\n",
      "Epoch 30/50\n",
      "6400/6400 [==============================] - 0s 7us/sample - loss: 0.5021 - accuracy: 0.7944\n",
      "Epoch 31/50\n",
      "6400/6400 [==============================] - 0s 7us/sample - loss: 0.5012 - accuracy: 0.7944\n",
      "Epoch 32/50\n",
      "6400/6400 [==============================] - 0s 7us/sample - loss: 0.5003 - accuracy: 0.7944\n",
      "Epoch 33/50\n",
      "6400/6400 [==============================] - 0s 7us/sample - loss: 0.4995 - accuracy: 0.7944\n",
      "Epoch 34/50\n",
      "6400/6400 [==============================] - 0s 7us/sample - loss: 0.4986 - accuracy: 0.7944\n",
      "Epoch 35/50\n",
      "6400/6400 [==============================] - 0s 8us/sample - loss: 0.4978 - accuracy: 0.7944\n",
      "Epoch 36/50\n",
      "6400/6400 [==============================] - 0s 8us/sample - loss: 0.4970 - accuracy: 0.7944\n",
      "Epoch 37/50\n",
      "6400/6400 [==============================] - 0s 7us/sample - loss: 0.4963 - accuracy: 0.7944\n",
      "Epoch 38/50\n",
      "6400/6400 [==============================] - 0s 7us/sample - loss: 0.4955 - accuracy: 0.7944\n",
      "Epoch 39/50\n",
      "6400/6400 [==============================] - 0s 8us/sample - loss: 0.4947 - accuracy: 0.7944\n",
      "Epoch 40/50\n",
      "6400/6400 [==============================] - 0s 7us/sample - loss: 0.4940 - accuracy: 0.7944\n",
      "Epoch 41/50\n",
      "6400/6400 [==============================] - 0s 7us/sample - loss: 0.4933 - accuracy: 0.7944\n",
      "Epoch 42/50\n",
      "6400/6400 [==============================] - 0s 8us/sample - loss: 0.4926 - accuracy: 0.7944\n",
      "Epoch 43/50\n",
      "6400/6400 [==============================] - 0s 8us/sample - loss: 0.4919 - accuracy: 0.7944\n",
      "Epoch 44/50\n",
      "6400/6400 [==============================] - 0s 8us/sample - loss: 0.4912 - accuracy: 0.7944\n",
      "Epoch 45/50\n",
      "6400/6400 [==============================] - 0s 7us/sample - loss: 0.4906 - accuracy: 0.7944\n",
      "Epoch 46/50\n",
      "6400/6400 [==============================] - 0s 8us/sample - loss: 0.4899 - accuracy: 0.7944\n",
      "Epoch 47/50\n",
      "6400/6400 [==============================] - 0s 7us/sample - loss: 0.4893 - accuracy: 0.7944\n",
      "Epoch 48/50\n",
      "6400/6400 [==============================] - 0s 7us/sample - loss: 0.4886 - accuracy: 0.7944\n",
      "Epoch 49/50\n",
      "6400/6400 [==============================] - 0s 7us/sample - loss: 0.4880 - accuracy: 0.7944\n",
      "Epoch 50/50\n",
      "6400/6400 [==============================] - 0s 7us/sample - loss: 0.4874 - accuracy: 0.7944\n",
      "Train on 6400 samples\n",
      "Epoch 1/50\n",
      "6400/6400 [==============================] - 1s 87us/sample - loss: 0.8858 - accuracy: 0.2441\n",
      "Epoch 2/50\n",
      "6400/6400 [==============================] - 0s 7us/sample - loss: 0.7773 - accuracy: 0.3470\n",
      "Epoch 3/50\n",
      "6400/6400 [==============================] - 0s 7us/sample - loss: 0.7060 - accuracy: 0.5002\n",
      "Epoch 4/50\n",
      "6400/6400 [==============================] - 0s 7us/sample - loss: 0.6575 - accuracy: 0.6475\n",
      "Epoch 5/50\n",
      "6400/6400 [==============================] - 0s 7us/sample - loss: 0.6235 - accuracy: 0.7255\n",
      "Epoch 6/50\n",
      "6400/6400 [==============================] - 0s 7us/sample - loss: 0.5988 - accuracy: 0.7602\n",
      "Epoch 7/50\n",
      "6400/6400 [==============================] - 0s 7us/sample - loss: 0.5805 - accuracy: 0.7791\n",
      "Epoch 8/50\n",
      "6400/6400 [==============================] - 0s 7us/sample - loss: 0.5667 - accuracy: 0.7892\n",
      "Epoch 9/50\n",
      "6400/6400 [==============================] - 0s 7us/sample - loss: 0.5559 - accuracy: 0.7942\n",
      "Epoch 10/50\n",
      "6400/6400 [==============================] - 0s 8us/sample - loss: 0.5477 - accuracy: 0.7944\n",
      "Epoch 11/50\n",
      "6400/6400 [==============================] - 0s 7us/sample - loss: 0.5416 - accuracy: 0.7945\n",
      "Epoch 12/50\n",
      "6400/6400 [==============================] - 0s 7us/sample - loss: 0.5366 - accuracy: 0.7945\n",
      "Epoch 13/50\n",
      "6400/6400 [==============================] - 0s 8us/sample - loss: 0.5326 - accuracy: 0.7945\n",
      "Epoch 14/50\n",
      "6400/6400 [==============================] - 0s 8us/sample - loss: 0.5293 - accuracy: 0.7945\n",
      "Epoch 15/50\n",
      "6400/6400 [==============================] - 0s 7us/sample - loss: 0.5267 - accuracy: 0.7945\n",
      "Epoch 16/50\n",
      "6400/6400 [==============================] - 0s 7us/sample - loss: 0.5243 - accuracy: 0.7945\n",
      "Epoch 17/50\n",
      "6400/6400 [==============================] - 0s 7us/sample - loss: 0.5223 - accuracy: 0.7945\n",
      "Epoch 18/50\n",
      "6400/6400 [==============================] - 0s 8us/sample - loss: 0.5204 - accuracy: 0.7945\n",
      "Epoch 19/50\n",
      "6400/6400 [==============================] - 0s 7us/sample - loss: 0.5187 - accuracy: 0.7945\n",
      "Epoch 20/50\n",
      "6400/6400 [==============================] - 0s 7us/sample - loss: 0.5172 - accuracy: 0.7945\n",
      "Epoch 21/50\n",
      "6400/6400 [==============================] - 0s 8us/sample - loss: 0.5159 - accuracy: 0.7945\n",
      "Epoch 22/50\n",
      "6400/6400 [==============================] - 0s 8us/sample - loss: 0.5146 - accuracy: 0.7945\n",
      "Epoch 23/50\n",
      "6400/6400 [==============================] - 0s 7us/sample - loss: 0.5134 - accuracy: 0.7945\n",
      "Epoch 24/50\n",
      "6400/6400 [==============================] - 0s 8us/sample - loss: 0.5123 - accuracy: 0.7945\n",
      "Epoch 25/50\n",
      "6400/6400 [==============================] - 0s 7us/sample - loss: 0.5112 - accuracy: 0.7945\n",
      "Epoch 26/50\n",
      "6400/6400 [==============================] - 0s 7us/sample - loss: 0.5101 - accuracy: 0.7945\n",
      "Epoch 27/50\n",
      "6400/6400 [==============================] - 0s 7us/sample - loss: 0.5091 - accuracy: 0.7945\n",
      "Epoch 28/50\n",
      "6400/6400 [==============================] - 0s 7us/sample - loss: 0.5082 - accuracy: 0.7945\n",
      "Epoch 29/50\n",
      "6400/6400 [==============================] - 0s 7us/sample - loss: 0.5073 - accuracy: 0.7945\n",
      "Epoch 30/50\n",
      "6400/6400 [==============================] - 0s 7us/sample - loss: 0.5064 - accuracy: 0.7945\n",
      "Epoch 31/50\n",
      "6400/6400 [==============================] - 0s 8us/sample - loss: 0.5055 - accuracy: 0.7945\n",
      "Epoch 32/50\n",
      "6400/6400 [==============================] - 0s 7us/sample - loss: 0.5046 - accuracy: 0.7945\n",
      "Epoch 33/50\n",
      "6400/6400 [==============================] - 0s 8us/sample - loss: 0.5037 - accuracy: 0.7945\n",
      "Epoch 34/50\n",
      "6400/6400 [==============================] - 0s 8us/sample - loss: 0.5029 - accuracy: 0.7945\n",
      "Epoch 35/50\n",
      "6400/6400 [==============================] - 0s 7us/sample - loss: 0.5021 - accuracy: 0.7945\n",
      "Epoch 36/50\n",
      "6400/6400 [==============================] - 0s 7us/sample - loss: 0.5013 - accuracy: 0.7945\n",
      "Epoch 37/50\n",
      "6400/6400 [==============================] - 0s 7us/sample - loss: 0.5005 - accuracy: 0.7945\n",
      "Epoch 38/50\n",
      "6400/6400 [==============================] - 0s 7us/sample - loss: 0.4997 - accuracy: 0.7945\n",
      "Epoch 39/50\n",
      "6400/6400 [==============================] - 0s 8us/sample - loss: 0.4990 - accuracy: 0.7945\n",
      "Epoch 40/50\n",
      "6400/6400 [==============================] - 0s 8us/sample - loss: 0.4982 - accuracy: 0.7945\n",
      "Epoch 41/50\n",
      "6400/6400 [==============================] - 0s 8us/sample - loss: 0.4975 - accuracy: 0.7945\n",
      "Epoch 42/50\n",
      "6400/6400 [==============================] - 0s 7us/sample - loss: 0.4968 - accuracy: 0.7945\n",
      "Epoch 43/50\n",
      "6400/6400 [==============================] - 0s 7us/sample - loss: 0.4961 - accuracy: 0.7945\n",
      "Epoch 44/50\n",
      "6400/6400 [==============================] - 0s 8us/sample - loss: 0.4954 - accuracy: 0.7945\n",
      "Epoch 45/50\n",
      "6400/6400 [==============================] - 0s 11us/sample - loss: 0.4947 - accuracy: 0.7945\n",
      "Epoch 46/50\n",
      "6400/6400 [==============================] - 0s 8us/sample - loss: 0.4940 - accuracy: 0.7945\n",
      "Epoch 47/50\n",
      "6400/6400 [==============================] - 0s 7us/sample - loss: 0.4934 - accuracy: 0.7945\n",
      "Epoch 48/50\n",
      "6400/6400 [==============================] - 0s 7us/sample - loss: 0.4927 - accuracy: 0.7945\n",
      "Epoch 49/50\n",
      "6400/6400 [==============================] - 0s 7us/sample - loss: 0.4921 - accuracy: 0.7945\n",
      "Epoch 50/50\n",
      "6400/6400 [==============================] - 0s 7us/sample - loss: 0.4914 - accuracy: 0.7945\n",
      "Train on 6400 samples\n",
      "Epoch 1/50\n",
      "6400/6400 [==============================] - 1s 92us/sample - loss: 0.7951 - accuracy: 0.2381\n",
      "Epoch 2/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6400/6400 [==============================] - 0s 7us/sample - loss: 0.7331 - accuracy: 0.3856\n",
      "Epoch 3/50\n",
      "6400/6400 [==============================] - 0s 7us/sample - loss: 0.6865 - accuracy: 0.5663\n",
      "Epoch 4/50\n",
      "6400/6400 [==============================] - 0s 7us/sample - loss: 0.6514 - accuracy: 0.6892\n",
      "Epoch 5/50\n",
      "6400/6400 [==============================] - 0s 7us/sample - loss: 0.6244 - accuracy: 0.7477\n",
      "Epoch 6/50\n",
      "6400/6400 [==============================] - 0s 7us/sample - loss: 0.6032 - accuracy: 0.7763\n",
      "Epoch 7/50\n",
      "6400/6400 [==============================] - 0s 7us/sample - loss: 0.5865 - accuracy: 0.7895\n",
      "Epoch 8/50\n",
      "6400/6400 [==============================] - 0s 7us/sample - loss: 0.5733 - accuracy: 0.7928\n",
      "Epoch 9/50\n",
      "6400/6400 [==============================] - 0s 7us/sample - loss: 0.5624 - accuracy: 0.7942\n",
      "Epoch 10/50\n",
      "6400/6400 [==============================] - 0s 7us/sample - loss: 0.5536 - accuracy: 0.7947\n",
      "Epoch 11/50\n",
      "6400/6400 [==============================] - 0s 7us/sample - loss: 0.5467 - accuracy: 0.7955\n",
      "Epoch 12/50\n",
      "6400/6400 [==============================] - 0s 7us/sample - loss: 0.5409 - accuracy: 0.7956\n",
      "Epoch 13/50\n",
      "6400/6400 [==============================] - 0s 7us/sample - loss: 0.5363 - accuracy: 0.7955\n",
      "Epoch 14/50\n",
      "6400/6400 [==============================] - 0s 7us/sample - loss: 0.5324 - accuracy: 0.7958\n",
      "Epoch 15/50\n",
      "6400/6400 [==============================] - 0s 8us/sample - loss: 0.5293 - accuracy: 0.7958\n",
      "Epoch 16/50\n",
      "6400/6400 [==============================] - 0s 7us/sample - loss: 0.5265 - accuracy: 0.7958\n",
      "Epoch 17/50\n",
      "6400/6400 [==============================] - 0s 8us/sample - loss: 0.5242 - accuracy: 0.7958\n",
      "Epoch 18/50\n",
      "6400/6400 [==============================] - 0s 8us/sample - loss: 0.5221 - accuracy: 0.7958\n",
      "Epoch 19/50\n",
      "6400/6400 [==============================] - 0s 7us/sample - loss: 0.5203 - accuracy: 0.7958\n",
      "Epoch 20/50\n",
      "6400/6400 [==============================] - 0s 8us/sample - loss: 0.5188 - accuracy: 0.7958\n",
      "Epoch 21/50\n",
      "6400/6400 [==============================] - 0s 7us/sample - loss: 0.5175 - accuracy: 0.7958\n",
      "Epoch 22/50\n",
      "6400/6400 [==============================] - 0s 7us/sample - loss: 0.5163 - accuracy: 0.7958\n",
      "Epoch 23/50\n",
      "6400/6400 [==============================] - 0s 7us/sample - loss: 0.5152 - accuracy: 0.7958\n",
      "Epoch 24/50\n",
      "6400/6400 [==============================] - 0s 7us/sample - loss: 0.5141 - accuracy: 0.7958\n",
      "Epoch 25/50\n",
      "6400/6400 [==============================] - 0s 7us/sample - loss: 0.5132 - accuracy: 0.7958\n",
      "Epoch 26/50\n",
      "6400/6400 [==============================] - 0s 7us/sample - loss: 0.5124 - accuracy: 0.7958\n",
      "Epoch 27/50\n",
      "6400/6400 [==============================] - 0s 7us/sample - loss: 0.5116 - accuracy: 0.7958\n",
      "Epoch 28/50\n",
      "6400/6400 [==============================] - 0s 7us/sample - loss: 0.5109 - accuracy: 0.7958\n",
      "Epoch 29/50\n",
      "6400/6400 [==============================] - 0s 8us/sample - loss: 0.5102 - accuracy: 0.7958\n",
      "Epoch 30/50\n",
      "6400/6400 [==============================] - 0s 8us/sample - loss: 0.5095 - accuracy: 0.7958\n",
      "Epoch 31/50\n",
      "6400/6400 [==============================] - 0s 7us/sample - loss: 0.5089 - accuracy: 0.7958\n",
      "Epoch 32/50\n",
      "6400/6400 [==============================] - 0s 7us/sample - loss: 0.5083 - accuracy: 0.7958\n",
      "Epoch 33/50\n",
      "6400/6400 [==============================] - 0s 7us/sample - loss: 0.5077 - accuracy: 0.7958\n",
      "Epoch 34/50\n",
      "6400/6400 [==============================] - 0s 7us/sample - loss: 0.5071 - accuracy: 0.7958\n",
      "Epoch 35/50\n",
      "6400/6400 [==============================] - 0s 8us/sample - loss: 0.5065 - accuracy: 0.7958\n",
      "Epoch 36/50\n",
      "6400/6400 [==============================] - 0s 7us/sample - loss: 0.5060 - accuracy: 0.7958\n",
      "Epoch 37/50\n",
      "6400/6400 [==============================] - 0s 8us/sample - loss: 0.5055 - accuracy: 0.7958\n",
      "Epoch 38/50\n",
      "6400/6400 [==============================] - 0s 7us/sample - loss: 0.5049 - accuracy: 0.7958\n",
      "Epoch 39/50\n",
      "6400/6400 [==============================] - 0s 8us/sample - loss: 0.5044 - accuracy: 0.7958\n",
      "Epoch 40/50\n",
      "6400/6400 [==============================] - 0s 7us/sample - loss: 0.5039 - accuracy: 0.7958\n",
      "Epoch 41/50\n",
      "6400/6400 [==============================] - 0s 8us/sample - loss: 0.5035 - accuracy: 0.7958\n",
      "Epoch 42/50\n",
      "6400/6400 [==============================] - 0s 7us/sample - loss: 0.5030 - accuracy: 0.7958\n",
      "Epoch 43/50\n",
      "6400/6400 [==============================] - 0s 7us/sample - loss: 0.5025 - accuracy: 0.7958\n",
      "Epoch 44/50\n",
      "6400/6400 [==============================] - 0s 7us/sample - loss: 0.5021 - accuracy: 0.7958\n",
      "Epoch 45/50\n",
      "6400/6400 [==============================] - 0s 7us/sample - loss: 0.5016 - accuracy: 0.7958\n",
      "Epoch 46/50\n",
      "6400/6400 [==============================] - 0s 7us/sample - loss: 0.5012 - accuracy: 0.7958\n",
      "Epoch 47/50\n",
      "6400/6400 [==============================] - 0s 7us/sample - loss: 0.5008 - accuracy: 0.7958\n",
      "Epoch 48/50\n",
      "6400/6400 [==============================] - 0s 8us/sample - loss: 0.5003 - accuracy: 0.7958\n",
      "Epoch 49/50\n",
      "6400/6400 [==============================] - 0s 8us/sample - loss: 0.4999 - accuracy: 0.7958\n",
      "Epoch 50/50\n",
      "6400/6400 [==============================] - 0s 7us/sample - loss: 0.4995 - accuracy: 0.7958\n",
      "Train on 6400 samples\n",
      "Epoch 1/50\n",
      "6400/6400 [==============================] - 1s 96us/sample - loss: 0.6651 - accuracy: 0.6242\n",
      "Epoch 2/50\n",
      "6400/6400 [==============================] - 0s 7us/sample - loss: 0.6198 - accuracy: 0.7563\n",
      "Epoch 3/50\n",
      "6400/6400 [==============================] - 0s 7us/sample - loss: 0.5882 - accuracy: 0.7902\n",
      "Epoch 4/50\n",
      "6400/6400 [==============================] - 0s 7us/sample - loss: 0.5658 - accuracy: 0.7973\n",
      "Epoch 5/50\n",
      "6400/6400 [==============================] - 0s 7us/sample - loss: 0.5494 - accuracy: 0.7980\n",
      "Epoch 6/50\n",
      "6400/6400 [==============================] - 0s 7us/sample - loss: 0.5373 - accuracy: 0.7975\n",
      "Epoch 7/50\n",
      "6400/6400 [==============================] - 0s 8us/sample - loss: 0.5283 - accuracy: 0.7973\n",
      "Epoch 8/50\n",
      "6400/6400 [==============================] - 0s 8us/sample - loss: 0.5216 - accuracy: 0.7975\n",
      "Epoch 9/50\n",
      "6400/6400 [==============================] - 0s 7us/sample - loss: 0.5163 - accuracy: 0.7975\n",
      "Epoch 10/50\n",
      "6400/6400 [==============================] - 0s 7us/sample - loss: 0.5122 - accuracy: 0.7975\n",
      "Epoch 11/50\n",
      "6400/6400 [==============================] - 0s 8us/sample - loss: 0.5090 - accuracy: 0.7975\n",
      "Epoch 12/50\n",
      "6400/6400 [==============================] - 0s 7us/sample - loss: 0.5064 - accuracy: 0.7975\n",
      "Epoch 13/50\n",
      "6400/6400 [==============================] - 0s 8us/sample - loss: 0.5043 - accuracy: 0.7975\n",
      "Epoch 14/50\n",
      "6400/6400 [==============================] - 0s 7us/sample - loss: 0.5025 - accuracy: 0.7975\n",
      "Epoch 15/50\n",
      "6400/6400 [==============================] - 0s 8us/sample - loss: 0.5010 - accuracy: 0.7975\n",
      "Epoch 16/50\n",
      "6400/6400 [==============================] - 0s 8us/sample - loss: 0.4995 - accuracy: 0.7975\n",
      "Epoch 17/50\n",
      "6400/6400 [==============================] - 0s 8us/sample - loss: 0.4983 - accuracy: 0.7975\n",
      "Epoch 18/50\n",
      "6400/6400 [==============================] - 0s 8us/sample - loss: 0.4971 - accuracy: 0.7975\n",
      "Epoch 19/50\n",
      "6400/6400 [==============================] - 0s 7us/sample - loss: 0.4961 - accuracy: 0.7975\n",
      "Epoch 20/50\n",
      "6400/6400 [==============================] - 0s 7us/sample - loss: 0.4951 - accuracy: 0.7975\n",
      "Epoch 21/50\n",
      "6400/6400 [==============================] - 0s 8us/sample - loss: 0.4942 - accuracy: 0.7975\n",
      "Epoch 22/50\n",
      "6400/6400 [==============================] - 0s 7us/sample - loss: 0.4933 - accuracy: 0.7975\n",
      "Epoch 23/50\n",
      "6400/6400 [==============================] - 0s 7us/sample - loss: 0.4925 - accuracy: 0.7975\n",
      "Epoch 24/50\n",
      "6400/6400 [==============================] - 0s 7us/sample - loss: 0.4917 - accuracy: 0.7975\n",
      "Epoch 25/50\n",
      "6400/6400 [==============================] - 0s 7us/sample - loss: 0.4909 - accuracy: 0.7975\n",
      "Epoch 26/50\n",
      "6400/6400 [==============================] - 0s 7us/sample - loss: 0.4901 - accuracy: 0.7975\n",
      "Epoch 27/50\n",
      "6400/6400 [==============================] - 0s 7us/sample - loss: 0.4894 - accuracy: 0.7975\n",
      "Epoch 28/50\n",
      "6400/6400 [==============================] - 0s 8us/sample - loss: 0.4887 - accuracy: 0.7975\n",
      "Epoch 29/50\n",
      "6400/6400 [==============================] - 0s 8us/sample - loss: 0.4880 - accuracy: 0.7975\n",
      "Epoch 30/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6400/6400 [==============================] - 0s 8us/sample - loss: 0.4873 - accuracy: 0.7975\n",
      "Epoch 31/50\n",
      "6400/6400 [==============================] - 0s 7us/sample - loss: 0.4866 - accuracy: 0.7975\n",
      "Epoch 32/50\n",
      "6400/6400 [==============================] - 0s 8us/sample - loss: 0.4859 - accuracy: 0.7975\n",
      "Epoch 33/50\n",
      "6400/6400 [==============================] - 0s 7us/sample - loss: 0.4852 - accuracy: 0.7975\n",
      "Epoch 34/50\n",
      "6400/6400 [==============================] - 0s 8us/sample - loss: 0.4846 - accuracy: 0.7975\n",
      "Epoch 35/50\n",
      "6400/6400 [==============================] - 0s 7us/sample - loss: 0.4839 - accuracy: 0.7975\n",
      "Epoch 36/50\n",
      "6400/6400 [==============================] - 0s 7us/sample - loss: 0.4833 - accuracy: 0.7975\n",
      "Epoch 37/50\n",
      "6400/6400 [==============================] - 0s 7us/sample - loss: 0.4827 - accuracy: 0.7975\n",
      "Epoch 38/50\n",
      "6400/6400 [==============================] - 0s 8us/sample - loss: 0.4821 - accuracy: 0.7975\n",
      "Epoch 39/50\n",
      "6400/6400 [==============================] - 0s 7us/sample - loss: 0.4815 - accuracy: 0.7975\n",
      "Epoch 40/50\n",
      "6400/6400 [==============================] - 0s 8us/sample - loss: 0.4809 - accuracy: 0.7975\n",
      "Epoch 41/50\n",
      "6400/6400 [==============================] - 0s 8us/sample - loss: 0.4803 - accuracy: 0.7975\n",
      "Epoch 42/50\n",
      "6400/6400 [==============================] - 0s 8us/sample - loss: 0.4797 - accuracy: 0.7975\n",
      "Epoch 43/50\n",
      "6400/6400 [==============================] - 0s 7us/sample - loss: 0.4792 - accuracy: 0.7975\n",
      "Epoch 44/50\n",
      "6400/6400 [==============================] - 0s 7us/sample - loss: 0.4786 - accuracy: 0.7975\n",
      "Epoch 45/50\n",
      "6400/6400 [==============================] - 0s 7us/sample - loss: 0.4781 - accuracy: 0.7975\n",
      "Epoch 46/50\n",
      "6400/6400 [==============================] - 0s 7us/sample - loss: 0.4775 - accuracy: 0.7975\n",
      "Epoch 47/50\n",
      "6400/6400 [==============================] - 0s 7us/sample - loss: 0.4770 - accuracy: 0.7975\n",
      "Epoch 48/50\n",
      "6400/6400 [==============================] - 0s 8us/sample - loss: 0.4765 - accuracy: 0.7975\n",
      "Epoch 49/50\n",
      "6400/6400 [==============================] - 0s 7us/sample - loss: 0.4760 - accuracy: 0.7975\n",
      "Epoch 50/50\n",
      "6400/6400 [==============================] - 0s 7us/sample - loss: 0.4755 - accuracy: 0.7975\n",
      "Train on 6400 samples\n",
      "Epoch 1/50\n",
      "6400/6400 [==============================] - 1s 96us/sample - loss: 0.5999 - accuracy: 0.7869\n",
      "Epoch 2/50\n",
      "6400/6400 [==============================] - 0s 7us/sample - loss: 0.5822 - accuracy: 0.7984\n",
      "Epoch 3/50\n",
      "6400/6400 [==============================] - 0s 7us/sample - loss: 0.5687 - accuracy: 0.8011\n",
      "Epoch 4/50\n",
      "6400/6400 [==============================] - 0s 7us/sample - loss: 0.5583 - accuracy: 0.8022\n",
      "Epoch 5/50\n",
      "6400/6400 [==============================] - 0s 7us/sample - loss: 0.5497 - accuracy: 0.8028\n",
      "Epoch 6/50\n",
      "6400/6400 [==============================] - 0s 7us/sample - loss: 0.5427 - accuracy: 0.8028\n",
      "Epoch 7/50\n",
      "6400/6400 [==============================] - 0s 8us/sample - loss: 0.5369 - accuracy: 0.8028\n",
      "Epoch 8/50\n",
      "6400/6400 [==============================] - 0s 7us/sample - loss: 0.5322 - accuracy: 0.8028\n",
      "Epoch 9/50\n",
      "6400/6400 [==============================] - 0s 8us/sample - loss: 0.5280 - accuracy: 0.8028\n",
      "Epoch 10/50\n",
      "6400/6400 [==============================] - 0s 7us/sample - loss: 0.5243 - accuracy: 0.8028\n",
      "Epoch 11/50\n",
      "6400/6400 [==============================] - 0s 7us/sample - loss: 0.5211 - accuracy: 0.8028\n",
      "Epoch 12/50\n",
      "6400/6400 [==============================] - 0s 8us/sample - loss: 0.5182 - accuracy: 0.8028\n",
      "Epoch 13/50\n",
      "6400/6400 [==============================] - 0s 7us/sample - loss: 0.5155 - accuracy: 0.8028\n",
      "Epoch 14/50\n",
      "6400/6400 [==============================] - 0s 7us/sample - loss: 0.5130 - accuracy: 0.8028\n",
      "Epoch 15/50\n",
      "6400/6400 [==============================] - 0s 7us/sample - loss: 0.5106 - accuracy: 0.8028\n",
      "Epoch 16/50\n",
      "6400/6400 [==============================] - 0s 7us/sample - loss: 0.5084 - accuracy: 0.8028\n",
      "Epoch 17/50\n",
      "6400/6400 [==============================] - 0s 8us/sample - loss: 0.5063 - accuracy: 0.8028\n",
      "Epoch 18/50\n",
      "6400/6400 [==============================] - 0s 7us/sample - loss: 0.5043 - accuracy: 0.8028\n",
      "Epoch 19/50\n",
      "6400/6400 [==============================] - 0s 7us/sample - loss: 0.5023 - accuracy: 0.8028\n",
      "Epoch 20/50\n",
      "6400/6400 [==============================] - 0s 7us/sample - loss: 0.5005 - accuracy: 0.8028\n",
      "Epoch 21/50\n",
      "6400/6400 [==============================] - 0s 7us/sample - loss: 0.4987 - accuracy: 0.8028\n",
      "Epoch 22/50\n",
      "6400/6400 [==============================] - 0s 8us/sample - loss: 0.4969 - accuracy: 0.8028\n",
      "Epoch 23/50\n",
      "6400/6400 [==============================] - 0s 7us/sample - loss: 0.4952 - accuracy: 0.8028\n",
      "Epoch 24/50\n",
      "6400/6400 [==============================] - 0s 7us/sample - loss: 0.4936 - accuracy: 0.8028\n",
      "Epoch 25/50\n",
      "6400/6400 [==============================] - 0s 8us/sample - loss: 0.4920 - accuracy: 0.8028\n",
      "Epoch 26/50\n",
      "6400/6400 [==============================] - 0s 7us/sample - loss: 0.4905 - accuracy: 0.8028\n",
      "Epoch 27/50\n",
      "6400/6400 [==============================] - 0s 8us/sample - loss: 0.4890 - accuracy: 0.8028\n",
      "Epoch 28/50\n",
      "6400/6400 [==============================] - 0s 9us/sample - loss: 0.4876 - accuracy: 0.8028\n",
      "Epoch 29/50\n",
      "6400/6400 [==============================] - 0s 7us/sample - loss: 0.4862 - accuracy: 0.8028\n",
      "Epoch 30/50\n",
      "6400/6400 [==============================] - 0s 8us/sample - loss: 0.4848 - accuracy: 0.8028\n",
      "Epoch 31/50\n",
      "6400/6400 [==============================] - 0s 8us/sample - loss: 0.4835 - accuracy: 0.8028\n",
      "Epoch 32/50\n",
      "6400/6400 [==============================] - 0s 8us/sample - loss: 0.4822 - accuracy: 0.8028\n",
      "Epoch 33/50\n",
      "6400/6400 [==============================] - 0s 9us/sample - loss: 0.4809 - accuracy: 0.8028\n",
      "Epoch 34/50\n",
      "6400/6400 [==============================] - 0s 9us/sample - loss: 0.4797 - accuracy: 0.8028\n",
      "Epoch 35/50\n",
      "6400/6400 [==============================] - 0s 7us/sample - loss: 0.4785 - accuracy: 0.8028\n",
      "Epoch 36/50\n",
      "6400/6400 [==============================] - 0s 7us/sample - loss: 0.4773 - accuracy: 0.8028\n",
      "Epoch 37/50\n",
      "6400/6400 [==============================] - 0s 8us/sample - loss: 0.4762 - accuracy: 0.8028\n",
      "Epoch 38/50\n",
      "6400/6400 [==============================] - 0s 7us/sample - loss: 0.4750 - accuracy: 0.8028\n",
      "Epoch 39/50\n",
      "6400/6400 [==============================] - 0s 7us/sample - loss: 0.4739 - accuracy: 0.8028\n",
      "Epoch 40/50\n",
      "6400/6400 [==============================] - 0s 8us/sample - loss: 0.4729 - accuracy: 0.8028\n",
      "Epoch 41/50\n",
      "6400/6400 [==============================] - 0s 8us/sample - loss: 0.4718 - accuracy: 0.8028\n",
      "Epoch 42/50\n",
      "6400/6400 [==============================] - 0s 8us/sample - loss: 0.4708 - accuracy: 0.8028\n",
      "Epoch 43/50\n",
      "6400/6400 [==============================] - 0s 8us/sample - loss: 0.4698 - accuracy: 0.8028\n",
      "Epoch 44/50\n",
      "6400/6400 [==============================] - 0s 8us/sample - loss: 0.4689 - accuracy: 0.8028\n",
      "Epoch 45/50\n",
      "6400/6400 [==============================] - 0s 7us/sample - loss: 0.4680 - accuracy: 0.8028\n",
      "Epoch 46/50\n",
      "6400/6400 [==============================] - 0s 7us/sample - loss: 0.4671 - accuracy: 0.8028\n",
      "Epoch 47/50\n",
      "6400/6400 [==============================] - 0s 9us/sample - loss: 0.4661 - accuracy: 0.8028\n",
      "Epoch 48/50\n",
      "6400/6400 [==============================] - 0s 7us/sample - loss: 0.4652 - accuracy: 0.8028\n",
      "Epoch 49/50\n",
      "6400/6400 [==============================] - 0s 8us/sample - loss: 0.4644 - accuracy: 0.8028\n",
      "Epoch 50/50\n",
      "6400/6400 [==============================] - 0s 8us/sample - loss: 0.4635 - accuracy: 0.8028\n",
      "Train on 8000 samples\n",
      "Epoch 1/50\n",
      "8000/8000 [==============================] - 1s 88us/sample - loss: 0.6412 - accuracy: 0.6486\n",
      "Epoch 2/50\n",
      "8000/8000 [==============================] - 0s 24us/sample - loss: 0.5037 - accuracy: 0.8005\n",
      "Epoch 3/50\n",
      "8000/8000 [==============================] - 0s 23us/sample - loss: 0.4842 - accuracy: 0.8004\n",
      "Epoch 4/50\n",
      "8000/8000 [==============================] - 0s 22us/sample - loss: 0.4746 - accuracy: 0.8016\n",
      "Epoch 5/50\n",
      "8000/8000 [==============================] - 0s 23us/sample - loss: 0.4676 - accuracy: 0.8045\n",
      "Epoch 6/50\n",
      "8000/8000 [==============================] - 0s 24us/sample - loss: 0.4619 - accuracy: 0.8049\n",
      "Epoch 7/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 25us/sample - loss: 0.4572 - accuracy: 0.8064\n",
      "Epoch 8/50\n",
      "8000/8000 [==============================] - 0s 24us/sample - loss: 0.4531 - accuracy: 0.8070\n",
      "Epoch 9/50\n",
      "8000/8000 [==============================] - 0s 22us/sample - loss: 0.4495 - accuracy: 0.8076\n",
      "Epoch 10/50\n",
      "8000/8000 [==============================] - 0s 22us/sample - loss: 0.4464 - accuracy: 0.8087\n",
      "Epoch 11/50\n",
      "8000/8000 [==============================] - 0s 21us/sample - loss: 0.4435 - accuracy: 0.8110\n",
      "Epoch 12/50\n",
      "8000/8000 [==============================] - 0s 22us/sample - loss: 0.4409 - accuracy: 0.8108\n",
      "Epoch 13/50\n",
      "8000/8000 [==============================] - 0s 23us/sample - loss: 0.4384 - accuracy: 0.8099\n",
      "Epoch 14/50\n",
      "8000/8000 [==============================] - 0s 22us/sample - loss: 0.4360 - accuracy: 0.8116\n",
      "Epoch 15/50\n",
      "8000/8000 [==============================] - 0s 21us/sample - loss: 0.4338 - accuracy: 0.8115\n",
      "Epoch 16/50\n",
      "8000/8000 [==============================] - 0s 22us/sample - loss: 0.4316 - accuracy: 0.8129\n",
      "Epoch 17/50\n",
      "8000/8000 [==============================] - 0s 21us/sample - loss: 0.4295 - accuracy: 0.8133\n",
      "Epoch 18/50\n",
      "8000/8000 [==============================] - 0s 21us/sample - loss: 0.4275 - accuracy: 0.8136\n",
      "Epoch 19/50\n",
      "8000/8000 [==============================] - 0s 22us/sample - loss: 0.4255 - accuracy: 0.8145\n",
      "Epoch 20/50\n",
      "8000/8000 [==============================] - 0s 23us/sample - loss: 0.4237 - accuracy: 0.8150\n",
      "Epoch 21/50\n",
      "8000/8000 [==============================] - 0s 22us/sample - loss: 0.4218 - accuracy: 0.8154\n",
      "Epoch 22/50\n",
      "8000/8000 [==============================] - 0s 22us/sample - loss: 0.4201 - accuracy: 0.8165\n",
      "Epoch 23/50\n",
      "8000/8000 [==============================] - 0s 22us/sample - loss: 0.4182 - accuracy: 0.8180\n",
      "Epoch 24/50\n",
      "8000/8000 [==============================] - 0s 22us/sample - loss: 0.4166 - accuracy: 0.8185\n",
      "Epoch 25/50\n",
      "8000/8000 [==============================] - 0s 22us/sample - loss: 0.4147 - accuracy: 0.8198\n",
      "Epoch 26/50\n",
      "8000/8000 [==============================] - 0s 21us/sample - loss: 0.4131 - accuracy: 0.8199\n",
      "Epoch 27/50\n",
      "8000/8000 [==============================] - 0s 22us/sample - loss: 0.4113 - accuracy: 0.8207\n",
      "Epoch 28/50\n",
      "8000/8000 [==============================] - 0s 22us/sample - loss: 0.4095 - accuracy: 0.8207\n",
      "Epoch 29/50\n",
      "8000/8000 [==============================] - 0s 21us/sample - loss: 0.4077 - accuracy: 0.8224\n",
      "Epoch 30/50\n",
      "8000/8000 [==============================] - 0s 22us/sample - loss: 0.4058 - accuracy: 0.8238\n",
      "Epoch 31/50\n",
      "8000/8000 [==============================] - 0s 21us/sample - loss: 0.4040 - accuracy: 0.8255\n",
      "Epoch 32/50\n",
      "8000/8000 [==============================] - 0s 21us/sample - loss: 0.4020 - accuracy: 0.8255\n",
      "Epoch 33/50\n",
      "8000/8000 [==============================] - 0s 21us/sample - loss: 0.4000 - accuracy: 0.8266\n",
      "Epoch 34/50\n",
      "8000/8000 [==============================] - 0s 22us/sample - loss: 0.3979 - accuracy: 0.8274\n",
      "Epoch 35/50\n",
      "8000/8000 [==============================] - 0s 21us/sample - loss: 0.3958 - accuracy: 0.8286\n",
      "Epoch 36/50\n",
      "8000/8000 [==============================] - 0s 22us/sample - loss: 0.3937 - accuracy: 0.8305\n",
      "Epoch 37/50\n",
      "8000/8000 [==============================] - 0s 22us/sample - loss: 0.3915 - accuracy: 0.8315\n",
      "Epoch 38/50\n",
      "8000/8000 [==============================] - 0s 22us/sample - loss: 0.3894 - accuracy: 0.8334\n",
      "Epoch 39/50\n",
      "8000/8000 [==============================] - 0s 22us/sample - loss: 0.3872 - accuracy: 0.8338\n",
      "Epoch 40/50\n",
      "8000/8000 [==============================] - 0s 22us/sample - loss: 0.3852 - accuracy: 0.8353\n",
      "Epoch 41/50\n",
      "8000/8000 [==============================] - 0s 21us/sample - loss: 0.3831 - accuracy: 0.8365\n",
      "Epoch 42/50\n",
      "8000/8000 [==============================] - 0s 21us/sample - loss: 0.3811 - accuracy: 0.8369\n",
      "Epoch 43/50\n",
      "8000/8000 [==============================] - 0s 21us/sample - loss: 0.3791 - accuracy: 0.8380\n",
      "Epoch 44/50\n",
      "8000/8000 [==============================] - 0s 22us/sample - loss: 0.3771 - accuracy: 0.8391\n",
      "Epoch 45/50\n",
      "8000/8000 [==============================] - 0s 23us/sample - loss: 0.3752 - accuracy: 0.8421\n",
      "Epoch 46/50\n",
      "8000/8000 [==============================] - 0s 23us/sample - loss: 0.3735 - accuracy: 0.8419\n",
      "Epoch 47/50\n",
      "8000/8000 [==============================] - 0s 22us/sample - loss: 0.3716 - accuracy: 0.8450\n",
      "Epoch 48/50\n",
      "8000/8000 [==============================] - 0s 21us/sample - loss: 0.3701 - accuracy: 0.8456\n",
      "Epoch 49/50\n",
      "8000/8000 [==============================] - 0s 21us/sample - loss: 0.3686 - accuracy: 0.8468\n",
      "Epoch 50/50\n",
      "8000/8000 [==============================] - 0s 22us/sample - loss: 0.3672 - accuracy: 0.8479\n"
     ]
    }
   ],
   "source": [
    "gs = GridSearchCV(model_KC, param_grid=param_grid,cv=5,scoring='accuracy')\n",
    "grid_result = gs.fit(X_train,y_train.argmax(axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.834375 using {'batch_size': 100, 'epochs': 50}\n",
      "0.796875 (0.012203) with: {'batch_size': 100, 'epochs': 1}\n",
      "0.801375 (0.017050) with: {'batch_size': 100, 'epochs': 10}\n",
      "0.834375 (0.010990) with: {'batch_size': 100, 'epochs': 50}\n",
      "0.539500 (0.170285) with: {'batch_size': 1000, 'epochs': 1}\n",
      "0.796750 (0.012446) with: {'batch_size': 1000, 'epochs': 10}\n",
      "0.797000 (0.012459) with: {'batch_size': 1000, 'epochs': 50}\n"
     ]
    }
   ],
   "source": [
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means,stds,params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RowNumber</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>619</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>608</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>502</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>699</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>850</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           CreditScore  Geography  Gender  Age  Tenure    Balance  \\\n",
       "RowNumber                                                           \n",
       "1                  619          0       0   42       2       0.00   \n",
       "2                  608          2       0   41       1   83807.86   \n",
       "3                  502          0       0   42       8  159660.80   \n",
       "4                  699          0       0   39       1       0.00   \n",
       "5                  850          2       0   43       2  125510.82   \n",
       "\n",
       "           NumOfProducts  HasCrCard  IsActiveMember  EstimatedSalary  Exited  \n",
       "RowNumber                                                                     \n",
       "1                      1          1               1        101348.88       1  \n",
       "2                      1          0               1        112542.58       0  \n",
       "3                      3          1               0        113931.57       1  \n",
       "4                      2          0               0         93826.63       0  \n",
       "5                      1          1               1         79084.10       0  "
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_drop.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1 = df_drop.copy(deep=True)\n",
    "Y_cv = df_1['Exited']\n",
    "X_cv = df_1.drop(['Exited'], axis=1)\n",
    "X_cv = X_cv.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7963001779001779\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<function sklearn.model_selection._validation.cross_val_score(estimator, X, y=None, groups=None, scoring=None, cv='warn', n_jobs=None, verbose=0, fit_params=None, pre_dispatch='2*n_jobs', error_score='raise-deprecating')>"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "model_KC_CV = KerasClassifier(build_fn=create_model,epochs=150, batch_size=10, verbose=0)\n",
    "\n",
    "kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=7)\n",
    "results = cross_val_score(model_KC_CV, X_cv, Y_cv, cv=kfold, scoring='accuracy')\n",
    "print(results.mean())\n",
    "cross_val_score"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Questions - Internal - R6 - AIML Labs",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
